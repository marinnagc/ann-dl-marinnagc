{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.2</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Marinna Grigolli Cesar</li> <li>Grupo<ul> <li>Marinna Grigolli Cesar</li> <li>Nicholas</li> <li>Guilherme</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 05/09/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"projeto/main/","title":"Main","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"roteiro1/exercises/","title":"Notebook 1 - Data","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Fixar semente para reprodutibilidade\nnp.random.seed(42)\n\n# N\u00famero de pontos por classe\nn = 100\n\n# Defini\u00e7\u00f5es das classes\nparams = {\n    0: {\"mean\": [2, 3], \"std\": [0.8, 2.5]},\n    1: {\"mean\": [5, 6], \"std\": [1.2, 1.9]},\n    2: {\"mean\": [8, 1], \"std\": [0.9, 0.9]},\n    3: {\"mean\": [15, 4], \"std\": [0.5, 2.0]}\n}\n</pre> import numpy as np import matplotlib.pyplot as plt  # Fixar semente para reprodutibilidade np.random.seed(42)  # N\u00famero de pontos por classe n = 100  # Defini\u00e7\u00f5es das classes params = {     0: {\"mean\": [2, 3], \"std\": [0.8, 2.5]},     1: {\"mean\": [5, 6], \"std\": [1.2, 1.9]},     2: {\"mean\": [8, 1], \"std\": [0.9, 0.9]},     3: {\"mean\": [15, 4], \"std\": [0.5, 2.0]} } In\u00a0[2]: Copied! <pre># Gerar dados\ndata = []\nlabels = []\nfor label, p in params.items():\n    x = np.random.normal(p[\"mean\"][0], p[\"std\"][0], n) # np.random.normal gera n\u00fameros aleat\u00f3rios com distribui\u00e7\u00e3o normal\n    y = np.random.normal(p[\"mean\"][1], p[\"std\"][1], n)\n    points = np.column_stack((x, y)) # Combina x e y em uma matriz n x 2, np.column_stack junta arrays como colunas\n    data.append(points)\n    labels.append(np.full(n, label)) # np.full cria um array preenchido com o valor do label\n\n# Concatenar tudo\nX = np.vstack(data) # np.vstack empilha arrays verticalmente\ny = np.hstack(labels) # np.hstack empilha arrays horizontalmente\n</pre> # Gerar dados data = [] labels = [] for label, p in params.items():     x = np.random.normal(p[\"mean\"][0], p[\"std\"][0], n) # np.random.normal gera n\u00fameros aleat\u00f3rios com distribui\u00e7\u00e3o normal     y = np.random.normal(p[\"mean\"][1], p[\"std\"][1], n)     points = np.column_stack((x, y)) # Combina x e y em uma matriz n x 2, np.column_stack junta arrays como colunas     data.append(points)     labels.append(np.full(n, label)) # np.full cria um array preenchido com o valor do label  # Concatenar tudo X = np.vstack(data) # np.vstack empilha arrays verticalmente y = np.hstack(labels) # np.hstack empilha arrays horizontalmente In\u00a0[3]: Copied! <pre># ---------- Plot ----------\nplt.figure(figsize=(9,7))\ncolors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n\n# Scatter de cada classe\nfor i, c in enumerate(colors):\n    plt.scatter(X[y==i, 0], X[y==i, 1], alpha=0.7, label=f'Classe {i}', color=c)\n\n# Criar valores no eixo X para desenhar as retas\nx_vals = np.linspace(X[:,0].min()-1, X[:,0].max()+1, 200)\n\n# ---------- Retas manuais (ajuste \u201cno olho\u201d) ----------\nplt.plot([3.1,3.1], [-2,12], 'k--', linewidth=1)   # entre Classe 0 e 1\nplt.plot([3.1,12.5], [1,5], 'k--', linewidth=1)  # entre Classe 1 e 2\nplt.plot([12.5,12.5], [-2,12], 'k--', linewidth=1)   # entre Classe 2 e 3\n\n# Ajustes do gr\u00e1fico\nplt.title(\"Distribui\u00e7\u00e3o das Classes e Fronteiras Lineares (esbo\u00e7adas)\")\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> # ---------- Plot ---------- plt.figure(figsize=(9,7)) colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']  # Scatter de cada classe for i, c in enumerate(colors):     plt.scatter(X[y==i, 0], X[y==i, 1], alpha=0.7, label=f'Classe {i}', color=c)  # Criar valores no eixo X para desenhar as retas x_vals = np.linspace(X[:,0].min()-1, X[:,0].max()+1, 200)  # ---------- Retas manuais (ajuste \u201cno olho\u201d) ---------- plt.plot([3.1,3.1], [-2,12], 'k--', linewidth=1)   # entre Classe 0 e 1 plt.plot([3.1,12.5], [1,5], 'k--', linewidth=1)  # entre Classe 1 e 2 plt.plot([12.5,12.5], [-2,12], 'k--', linewidth=1)   # entre Classe 2 e 3  # Ajustes do gr\u00e1fico plt.title(\"Distribui\u00e7\u00e3o das Classes e Fronteiras Lineares (esbo\u00e7adas)\") plt.xlabel(\"X1\") plt.ylabel(\"X2\") plt.legend() plt.grid(True) plt.show() In\u00a0[14]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# M\u00e9dias\nmu_A = np.array([0, 0, 0, 0, 0])\nmu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\n\n# Matrizes de covari\u00e2ncia\nSigma_A = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0]\n])\n\nSigma_B = np.array([\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5]\n])\n</pre> import numpy as np import matplotlib.pyplot as plt  np.random.seed(42)  # M\u00e9dias mu_A = np.array([0, 0, 0, 0, 0]) mu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])  # Matrizes de covari\u00e2ncia Sigma_A = np.array([     [1.0, 0.8, 0.1, 0.0, 0.0],     [0.8, 1.0, 0.3, 0.0, 0.0],     [0.1, 0.3, 1.0, 0.5, 0.0],     [0.0, 0.0, 0.5, 1.0, 0.2],     [0.0, 0.0, 0.0, 0.2, 1.0] ])  Sigma_B = np.array([     [1.5, -0.7, 0.2, 0.0, 0.0],     [-0.7, 1.5, 0.4, 0.0, 0.0],     [0.2, 0.4, 1.5, 0.6, 0.0],     [0.0, 0.0, 0.6, 1.5, 0.3],     [0.0, 0.0, 0.0, 0.3, 1.5] ])   In\u00a0[15]: Copied! <pre># Amostras\nn = 500\nXA = np.random.multivariate_normal(mu_A, Sigma_A, size=n)\nXB = np.random.multivariate_normal(mu_B, Sigma_B, size=n)\n\n# Dataset completo\nX = np.vstack([XA, XB])              # (1000, 5)\ny = np.hstack([np.zeros(n), np.ones(n)])  # r\u00f3tulos\n</pre> # Amostras n = 500 XA = np.random.multivariate_normal(mu_A, Sigma_A, size=n) XB = np.random.multivariate_normal(mu_B, Sigma_B, size=n)  # Dataset completo X = np.vstack([XA, XB])              # (1000, 5) y = np.hstack([np.zeros(n), np.ones(n)])  # r\u00f3tulos   <p>Use a technique like Principal Component Analysis (PCA) to project the 5D data down to 2 dimensions. Create a scatter plot of this 2D representation, coloring the points by their class (A or B).</p> In\u00a0[16]: Copied! <pre># ===== PCA do zero =====\n# Centralizar\nXc = X - X.mean(axis=0)\n\n# Covari\u00e2ncia\nCov = np.cov(Xc, rowvar=False)\n\n# Autovalores e autovetores\nvals, vecs = np.linalg.eigh(Cov)\n\n# Ordenar\norder = np.argsort(vals)[::-1]\nvecs = vecs[:, order]\nvals = vals[order]\n\n# Projetar nos 2 primeiros PCs\nW = vecs[:, :2]\nZ = Xc @ W\n# ======================\n</pre> # ===== PCA do zero ===== # Centralizar Xc = X - X.mean(axis=0)  # Covari\u00e2ncia Cov = np.cov(Xc, rowvar=False)  # Autovalores e autovetores vals, vecs = np.linalg.eigh(Cov)  # Ordenar order = np.argsort(vals)[::-1] vecs = vecs[:, order] vals = vals[order]  # Projetar nos 2 primeiros PCs W = vecs[:, :2] Z = Xc @ W # ======================  In\u00a0[17]: Copied! <pre># Plotar\nplt.figure(figsize=(7,6))\nplt.scatter(Z[y==0,0], Z[y==0,1], s=14, alpha=0.7, label=\"Class A\")\nplt.scatter(Z[y==1,0], Z[y==1,1], s=14, alpha=0.7, label=\"Class B\")\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\n\nvar_exp = 100 * vals[:2].sum() / vals.sum()\nplt.title(f\"PCA 2D (vari\u00e2ncia explicada: {var_exp:.1f}%)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> # Plotar plt.figure(figsize=(7,6)) plt.scatter(Z[y==0,0], Z[y==0,1], s=14, alpha=0.7, label=\"Class A\") plt.scatter(Z[y==1,0], Z[y==1,1], s=14, alpha=0.7, label=\"Class B\") plt.xlabel(\"PC1\") plt.ylabel(\"PC2\")  var_exp = 100 * vals[:2].sum() / vals.sum() plt.title(f\"PCA 2D (vari\u00e2ncia explicada: {var_exp:.1f}%)\") plt.legend() plt.grid(True) plt.show()  <p>Dataset Description (Spaceship Titanic) Objetivo</p> <p>O dataset tem como objetivo prever se um passageiro foi transportado para outra dimens\u00e3o durante a colis\u00e3o da Spaceship Titanic com a anomalia do espa\u00e7o-tempo.</p> <p>A coluna Transported \u00e9 a vari\u00e1vel-alvo (target), representando:</p> <p>True \u2192 passageiro foi transportado.</p> <p>False \u2192 passageiro n\u00e3o foi transportado.</p> <p>Vari\u00e1veis (features)</p> <pre><code>Identifica\u00e7\u00e3o</code></pre> <p>PassengerId: Identificador \u00fanico de cada passageiro. N\u00e3o \u00e9 uma feature preditiva em si, mas pode ser usado para agrupar fam\u00edlias.</p> <pre><code>Categ\u00f3ricas (valores discretos / n\u00e3o num\u00e9ricos)</code></pre> <p>HomePlanet: Planeta de origem.</p> <p>CryoSleep: Indica se o passageiro estava em sono criog\u00eanico (True/False).</p> <p>Cabin: N\u00famero da cabine (pode ser decomposta em deck, num e side).</p> <p>Destination: Planeta de destino.</p> <p>VIP: Passageiro contratou servi\u00e7o VIP (True/False).</p> <p>Name: Nome do passageiro (pouco \u00fatil como feature, pode ser descartado ou usado apenas para engenharia de features).</p> <pre><code>Num\u00e9ricas (valores cont\u00ednuos / quantitativos)</code></pre> <p>Age: Idade.</p> <p>RoomService: Valor gasto em servi\u00e7o de quarto.</p> <p>FoodCourt: Valor gasto no restaurante.</p> <p>ShoppingMall: Valor gasto no shopping.</p> <p>Spa: Valor gasto no spa.</p> <p>VRDeck: Valor gasto no deck de realidade virtual.</p> <p>Target (vari\u00e1vel resposta)</p> <p>Transported: Passageiro foi transportado (True ou False).</p> In\u00a0[18]: Copied! <pre>import pandas as pd\n\n# Carregar dataset\ndf = pd.read_csv(\"spaceship-titanic/train.csv\")\n\n# Contar valores ausentes por coluna\nmissing = df.isnull().sum()\nprint(missing)\n</pre> import pandas as pd  # Carregar dataset df = pd.read_csv(\"spaceship-titanic/train.csv\")  # Contar valores ausentes por coluna missing = df.isnull().sum() print(missing) <pre>PassengerId       0\nHomePlanet      201\nCryoSleep       217\nCabin           199\nDestination     182\nAge             179\nVIP             203\nRoomService     181\nFoodCourt       183\nShoppingMall    208\nSpa             183\nVRDeck          188\nName            200\nTransported       0\ndtype: int64\n</pre> <p>Valores ausentes</p> <p>No Kaggle, sabemos que o dataset tem missing values em v\u00e1rias colunas. Por exemplo:</p> <p>Age \u2192 alguns passageiros n\u00e3o t\u00eam idade registrada.</p> <p>Cabin \u2192 muitos registros est\u00e3o vazios.</p> <p>HomePlanet \u2192 h\u00e1 valores ausentes.</p> <p>CryoSleep e VIP \u2192 tamb\u00e9m t\u00eam valores faltantes.</p> <p>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck \u2192 v\u00e1rios passageiros t\u00eam valores nulos (pode ser gasto zero ou dado faltante).</p> In\u00a0[19]: Copied! <pre>import warnings\n\n# Fill numeric with median\nfor col in [\"Age\",\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]:\n    df[col].fillna(df[col].median(), inplace=True)\n\n# Fill categorical with mode\nfor col in [\"HomePlanet\",\"Destination\"]:\n    df[col].fillna(df[col].mode()[0], inplace=True)\n\n# Binary categorical\nfor col in [\"CryoSleep\",\"VIP\"]:\n    df[col].fillna(df[col].mode()[0], inplace=True)\n\n# Cabin -&gt; split\ndf[\"Deck\"] = df[\"Cabin\"].str[0]\ndf[\"Side\"] = df[\"Cabin\"].str[-1]\ndf.drop(columns=[\"Cabin\",\"Name\",\"PassengerId\"], inplace=True)\ndf[\"Deck\"].fillna(\"Unknown\", inplace=True)\ndf[\"Side\"].fillna(\"Unknown\", inplace=True)\nwarnings.filterwarnings(\"ignore\")\n</pre> import warnings  # Fill numeric with median for col in [\"Age\",\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]:     df[col].fillna(df[col].median(), inplace=True)  # Fill categorical with mode for col in [\"HomePlanet\",\"Destination\"]:     df[col].fillna(df[col].mode()[0], inplace=True)  # Binary categorical for col in [\"CryoSleep\",\"VIP\"]:     df[col].fillna(df[col].mode()[0], inplace=True)  # Cabin -&gt; split df[\"Deck\"] = df[\"Cabin\"].str[0] df[\"Side\"] = df[\"Cabin\"].str[-1] df.drop(columns=[\"Cabin\",\"Name\",\"PassengerId\"], inplace=True) df[\"Deck\"].fillna(\"Unknown\", inplace=True) df[\"Side\"].fillna(\"Unknown\", inplace=True) warnings.filterwarnings(\"ignore\") In\u00a0[10]: Copied! <pre>from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nnum_cols = [\"Age\",\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n</pre> from sklearn.preprocessing import StandardScaler  scaler = StandardScaler() num_cols = [\"Age\",\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"] df[num_cols] = scaler.fit_transform(df[num_cols])  In\u00a0[11]: Copied! <pre>import numpy as np\n\nnum_cols = [\"Age\",\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n\nfor col in num_cols:\n    mean = df[col].mean()\n    std = df[col].std()\n    df[col] = (df[col] - mean) / std\n</pre> import numpy as np  num_cols = [\"Age\",\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]  for col in num_cols:     mean = df[col].mean()     std = df[col].std()     df[col] = (df[col] - mean) / std In\u00a0[12]: Copied! <pre>import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 2, figsize=(10,6))\n\n# Age antes\ndf_raw = pd.read_csv(\"spaceship-titanic/train.csv\")\naxes[0,0].hist(df_raw[\"Age\"].dropna(), bins=30, color=\"skyblue\")\naxes[0,0].set_title(\"Age - Before Scaling\")\n\n# Age depois\naxes[0,1].hist(df[\"Age\"], bins=30, color=\"green\")\naxes[0,1].set_title(\"Age - After Scaling\")\n\n# FoodCourt antes\naxes[1,0].hist(df_raw[\"FoodCourt\"].dropna(), bins=30, color=\"skyblue\")\naxes[1,0].set_title(\"FoodCourt - Before Scaling\")\n\n# FoodCourt depois\naxes[1,1].hist(df[\"FoodCourt\"], bins=30, color=\"green\")\naxes[1,1].set_title(\"FoodCourt - After Scaling\")\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt  fig, axes = plt.subplots(2, 2, figsize=(10,6))  # Age antes df_raw = pd.read_csv(\"spaceship-titanic/train.csv\") axes[0,0].hist(df_raw[\"Age\"].dropna(), bins=30, color=\"skyblue\") axes[0,0].set_title(\"Age - Before Scaling\")  # Age depois axes[0,1].hist(df[\"Age\"], bins=30, color=\"green\") axes[0,1].set_title(\"Age - After Scaling\")  # FoodCourt antes axes[1,0].hist(df_raw[\"FoodCourt\"].dropna(), bins=30, color=\"skyblue\") axes[1,0].set_title(\"FoodCourt - Before Scaling\")  # FoodCourt depois axes[1,1].hist(df[\"FoodCourt\"], bins=30, color=\"green\") axes[1,1].set_title(\"FoodCourt - After Scaling\")  plt.tight_layout() plt.show()"},{"location":"roteiro1/exercises/#notebook-1-data","title":"Notebook 1 - Data\u00b6","text":"<p>Activity: Data Preparation and Analysis for Neural Networks</p> <p>This activity is designed to test your skills in generating synthetic datasets, handling real-world data challenges, and preparing data to be fed into neural networks.</p>"},{"location":"roteiro1/exercises/#exercise-1","title":"Exercise 1\u00b6","text":"<p>Exploring Class Separability in 2D</p> <p>Understanding how data is distributed is the first step before designing a network architecture. In this exercise, you will generate and visualize a two-dimensional dataset to explore how data distribution affects the complexity of the decision boundaries a neural network would need to learn.</p>"},{"location":"roteiro1/exercises/#11-generate-the-data","title":"1.1 Generate the Data:\u00b6","text":"<p>Create a synthetic dataset with a total of 400 samples, divided equally among 4 classes (100 samples each). Use a Gaussian distribution to generate the points for each class based on the following parameters:</p>"},{"location":"roteiro1/exercises/#12-plot-the-data","title":"1.2 Plot the Data:\u00b6","text":"<p>Create a 2D scatter plot showing all the data points. Use a different color for each class to make them distinguishable.</p>"},{"location":"roteiro1/exercises/#13-analyze-and-draw-boundaries","title":"1.3 Analyze and Draw Boundaries:\u00b6","text":"<p>a. Examine the scatter plot carefully. Describe the distribution and overlap of the four classes.</p> <p>b. Based on your visual inspection, could a simple, linear boundary separate all classes?</p> <p>c. On your plot, sketch the decision boundaries that you think a trained neural network might learn to separate these classes.</p>"},{"location":"roteiro1/exercises/#exercise-2","title":"Exercise 2\u00b6","text":"<p>Non-Linearity in Higher Dimensions</p> <p>Simple neural networks (like a Perceptron) can only learn linear boundaries. Deep networks excel when data is not linearly separable. This exercise challenges you to create and visualize such a dataset.</p>"},{"location":"roteiro1/exercises/#21-generate-the-data","title":"2.1 Generate the Data:\u00b6","text":"<p>Create a dataset with 500 samples for Class A and 500 samples for Class B. Use a multivariate normal distribution with the following parameters:</p>"},{"location":"roteiro1/exercises/#visualize-the-data","title":"Visualize the Data:\u00b6","text":"<p>Since you cannot directly plot a 5D graph, you must reduce its dimensionality.</p>"},{"location":"roteiro1/exercises/#analyze-the-plots","title":"Analyze the Plots:\u00b6","text":"<p>a. Based on your 2D projection, describe the relationship between the two classes.</p> <p>b. Discuss the linear separability of the data. Explain why this type of data structure poses a challenge for simple linear models and would likely require a multi-layer neural network with non-linear activation functions to be classified accurately.</p>"},{"location":"roteiro1/exercises/#exercise-3","title":"Exercise 3\u00b6","text":""},{"location":"roteiro1/exercises/#preparing-real-world-data-for-a-neural-network","title":"Preparing Real-World Data for a Neural Network\u00b6","text":"<p>This exercise uses a real dataset from Kaggle. Your task is to perform the necessary preprocessing to make it suitable for a neural network that uses the hyperbolic tangent (tanh) activation function in its hidden layers.</p>"},{"location":"roteiro1/exercises/#dataset-spaceship-titanic","title":"DATASET: Spaceship Titanic\u00b6","text":""},{"location":"roteiro1/exercises/#31-preprocessing","title":"3.1 Preprocessing\u00b6","text":"<p>a) Handling Missing Data</p> <p>Num\u00e9ricas (Age, gastos) \u2192 substituir pela mediana (mais robusta a outliers).</p> <p>Categ\u00f3ricas (HomePlanet, Destination) \u2192 substituir pelo valor mais frequente (mode).</p> <p>Bin\u00e1rias (CryoSleep, VIP) \u2192 preencher com False ou pelo mode.</p> <p>Cabin \u2192 separar em Deck e Side; valores ausentes tratados como categoria \"Unknown\".</p>"},{"location":"roteiro1/exercises/#32-normalize-standardize-numerical-features","title":"3.2 Normalize / Standardize Numerical Features\u00b6","text":"<p>Como vamos usar tanh, \u00e9 melhor que os dados estejam centrados em 0 e dentro de uma escala compar\u00e1vel.</p> <p>Op\u00e7\u00e3o 1: Padroniza\u00e7\u00e3o (Z-score) \u2192 m\u00e9dia = 0, desvio = 1.</p> <p>Op\u00e7\u00e3o 2: Normaliza\u00e7\u00e3o [-1, 1].</p> <p>Aqui vou usar Z-score:</p>"},{"location":"roteiro1/exercises/#33-visualizacao-antes-e-depois","title":"3.3 Visualiza\u00e7\u00e3o (antes e depois)\u00b6","text":"<p>Exemplo para Age e FoodCourt:</p>"},{"location":"roteiro1/main/","title":"1. Data","text":"<p>Atividade: Prepara\u00e7\u00e3o e An\u00e1lise de Dados para Redes Neurais</p> <p>Esta atividade foi projetada para testar suas habilidades na gera\u00e7\u00e3o de conjuntos de dados sint\u00e9ticos, no tratamento de desafios de dados do mundo real e na prepara\u00e7\u00e3o de dados para serem inseridos em redes neurais.</p>"},{"location":"roteiro1/main/#11-analisar-e-tracar-limites","title":"1.1 Analisar e Tra\u00e7ar Limites","text":"<p>(Exerc\u00edcio 1)</p> <p>Neste exerc\u00edcio exploramos a separabilidade em 2D para entender como diferentes distribui\u00e7\u00f5es de classes afetam a defini\u00e7\u00e3o de fronteiras de decis\u00e3o.</p> <p></p> <p>Distribui\u00e7\u00e3o das classes:</p> <ul> <li>A Classe 0 (azul) est\u00e1 concentrada em torno do ponto <code>[2, 3]</code>, com maior dispers\u00e3o no eixo vertical (X2).</li> <li>A Classe 1 (laranja) aparece pr\u00f3xima a <code>[5, 6]</code>, relativamente mais acima, mas parcialmente sobreposta \u00e0 Classe 0 no eixo X1.</li> <li>A Classe 2 (verde) est\u00e1 em <code>[8, 1]</code>, mais isolada, formando um cluster compacto e bem separado das Classes 0 e 1.</li> <li>A Classe 3 (vermelha) est\u00e1 distante, em <code>[15, 4]</code>, praticamente sem sobreposi\u00e7\u00e3o com as demais.</li> </ul> <p>Sobreposi\u00e7\u00e3o:</p> <ul> <li>Existe sobreposi\u00e7\u00e3o vis\u00edvel entre Classe 0 e Classe 1, principalmente nos limites superiores e inferiores.</li> <li>As Classes 2 e 3 aparecem mais isoladas e s\u00e3o mais facilmente separ\u00e1veis.</li> </ul> <p>Limites lineares:</p> <ul> <li>Uma \u00fanica fronteira linear n\u00e3o conseguiria separar todas as classes simultaneamente.</li> <li> <p>Algumas classes, no entanto, poderiam ser separadas com limites simples:</p> </li> <li> <p>Classe 3 pode ser isolada com uma linha vertical.</p> </li> <li>Classe 2 pode ser separada da Classe 0/1 com uma linha inclinada.</li> <li>Classe 0 e 1 exigem uma fronteira mais complexa devido \u00e0 sobreposi\u00e7\u00e3o.</li> </ul> <p>Rede Neural:</p> <ul> <li>Uma rede neural com fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o lineares (ex.: <code>tanh</code> ou <code>ReLU</code>) poderia aprender fronteiras curvas para separar Classe 0 e Classe 1 com maior precis\u00e3o.</li> <li>Assim, enquanto limites lineares funcionam para parte do espa\u00e7o, apenas uma rede neural \u00e9 capaz de capturar fronteiras mais flex\u00edveis e reduzir erros nas regi\u00f5es de sobreposi\u00e7\u00e3o.</li> </ul>"},{"location":"roteiro1/main/#12-nao-linearidade-em-dimensoes-superiores","title":"1.2 N\u00e3o-linearidade em dimens\u00f5es superiores","text":"<p>(Exerc\u00edcio 2)</p> <p>Este exerc\u00edcio demonstra a import\u00e2ncia da redu\u00e7\u00e3o de dimensionalidade e mostra como dados em dimens\u00f5es mais altas podem se tornar complexos para modelos lineares.</p> <p></p> <p>Relacionamento entre as classes:</p> <p>Na proje\u00e7\u00e3o 2D obtida via PCA, as Classes A (azul) e B (laranja) aparecem como dois grupos com regi\u00f5es predominantes distintas. A Classe A se concentra mais \u00e0 direita do eixo PC1, enquanto a Classe B aparece mais \u00e0 esquerda. Entretanto, h\u00e1 uma regi\u00e3o central significativa em que os pontos das duas classes se sobrep\u00f5em, indicando que n\u00e3o existe separa\u00e7\u00e3o perfeita na proje\u00e7\u00e3o.</p> <p>Separabilidade linear:</p> <p>Os dados n\u00e3o s\u00e3o totalmente separ\u00e1veis por uma fronteira linear simples. Uma reta at\u00e9 poderia dividir aproximadamente as classes em lados opostos, mas haveria muitos erros de classifica\u00e7\u00e3o devido \u00e0 sobreposi\u00e7\u00e3o. Isso mostra que modelos lineares n\u00e3o conseguem capturar toda a complexidade da distribui\u00e7\u00e3o.</p> <p>Por que \u00e9 um desafio para modelos lineares:</p> <p>Esse tipo de estrutura de dados \u00e9 desafiador porque as classes n\u00e3o seguem fronteiras lineares bem definidas. A diferen\u00e7a de covari\u00e2ncias faz com que os aglomerados tenham formatos e dispers\u00f5es distintas, e a proje\u00e7\u00e3o em 2D comprime ainda mais a separabilidade. Assim, um modelo linear simples n\u00e3o seria capaz de tra\u00e7ar fronteiras adequadas, enquanto uma rede neural multicamadas com fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o lineares pode aprender fronteiras de decis\u00e3o curvas e adaptativas, reduzindo os erros nas \u00e1reas de sobreposi\u00e7\u00e3o.</p>"},{"location":"roteiro1/main/#13-preparando-dados-do-mundo-real-para-uma-rede-neural","title":"1.3 Preparando dados do mundo real para uma rede neural","text":"<p>(Exerc\u00edcio 3)</p> <p>Este exerc\u00edcio usa o dataset real Spaceship Titanic para demonstrar como dados brutos precisam ser limpos e transformados antes de alimentar uma rede neural com fun\u00e7\u00e3o de ativa\u00e7\u00e3o <code>tanh</code>.</p> <p></p> <p>Objetivo do dataset Spaceship Titanic:</p> <ul> <li>Prever se um passageiro foi transportado para outra dimens\u00e3o ap\u00f3s a colis\u00e3o da nave.</li> <li>A vari\u00e1vel alvo \u00e9 <code>Transported</code>, bin\u00e1ria (<code>True</code>/<code>False</code>).</li> </ul> <p>Features:</p> <ul> <li>Num\u00e9ricas: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>.</li> <li>Categ\u00f3ricas: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Cabin</code> (decomposta em <code>Deck</code> e <code>Side</code>), <code>Destination</code>, <code>VIP</code>, <code>Name</code>.</li> </ul> <p>Valores ausentes:</p> <ul> <li>Detectados em diversas colunas: <code>Age</code>, <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, <code>VIP</code>, <code>Cabin</code> e nos gastos (<code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>).</li> <li>Isso refor\u00e7a a necessidade de um pr\u00e9-processamento adequado antes do treino.</li> </ul> <p>Tratamento de missing values:</p> <ul> <li>Num\u00e9ricas: preenchidas com a mediana (robusta a outliers).</li> <li>Categ\u00f3ricas: substitu\u00eddas pelo valor mais frequente (mode).</li> <li>Booleanas: (<code>CryoSleep</code>, <code>VIP</code>) \u2192 preenchidas com <code>False</code>.</li> <li> <p>Cabin: decomposta em <code>Deck</code> e <code>Side</code>, ausentes preenchidos como <code>\"Unknown\"</code>.</p> </li> <li> <p>Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas:</p> </li> <li> <p>Aplicado One-Hot Encoding, criando colunas bin\u00e1rias para cada categoria.</p> </li> <li>Essa abordagem evita impor rela\u00e7\u00f5es artificiais entre categorias (ex.: <code>HomePlanet</code> \u2260 ordinal).</li> </ul> <p>Escalonamento (scaling):</p> <ul> <li>Aplicada padroniza\u00e7\u00e3o (Z-score) \u00e0s vari\u00e1veis num\u00e9ricas.</li> <li>F\u00f3rmula: \\(x' = \\frac{x - \\mu}{\\sigma}\\).</li> <li>Justificativa: como a fun\u00e7\u00e3o de ativa\u00e7\u00e3o tanh gera sa\u00eddas em [-1,1] e \u00e9 centrada em 0, dados padronizados aceleram o aprendizado e evitam satura\u00e7\u00e3o em valores extremos.</li> </ul> <p>Resultados dos gr\u00e1ficos (antes vs depois do scaling):</p> <ul> <li>Age: antes variava de 0 a 80, concentrada entre 20\u201340. Depois do scaling, a distribui\u00e7\u00e3o ficou centrada em 0, variando entre aproximadamente -2 e +3. Isso mostra que a padroniza\u00e7\u00e3o funcionou corretamente.</li> <li>FoodCourt: antes apresentava forte assimetria, com a maioria dos valores pr\u00f3ximos de 0 e alguns passageiros com gastos alt\u00edssimos (outliers acima de 20.000). Depois do scaling, a vari\u00e1vel tamb\u00e9m ficou ajustada em torno de 0, mas a assimetria permaneceu vis\u00edvel, evidenciando que o Z-score n\u00e3o elimina outliers, apenas ajusta escala e m\u00e9dia.</li> <li>Essa an\u00e1lise mostra que vari\u00e1veis como <code>Age</code> ficam mais bem distribu\u00eddas ap\u00f3s padroniza\u00e7\u00e3o, enquanto vari\u00e1veis de gastos poderiam se beneficiar de uma transforma\u00e7\u00e3o extra (ex.: log) antes do scaling.</li> </ul> <p>Conclus\u00e3o \u2013 impacto do pr\u00e9-processamento</p> <p>O pr\u00e9-processamento foi essencial para tornar o conjunto de dados adequado ao treinamento de uma rede neural com fun\u00e7\u00e3o de ativa\u00e7\u00e3o <code>tanh</code>. O tratamento de valores ausentes garantiu consist\u00eancia, enquanto a codifica\u00e7\u00e3o one-hot transformou vari\u00e1veis categ\u00f3ricas em formato num\u00e9rico sem distor\u00e7\u00f5es. A padroniza\u00e7\u00e3o centrou e normalizou as vari\u00e1veis num\u00e9ricas, alinhando-as \u00e0 faixa de sa\u00edda da <code>tanh</code> ([-1,1]) e facilitando a converg\u00eancia do modelo. A an\u00e1lise gr\u00e1fica mostrou ganhos claros, como no caso de <code>Age</code>, que ficou bem distribu\u00edda ap\u00f3s o scaling, e destacou limita\u00e7\u00f5es, como em <code>FoodCourt</code>, onde outliers mantiveram a assimetria. No geral, o processo resultou em dados limpos, consistentes e devidamente escalados, formando uma base s\u00f3lida para o treinamento de redes neurais.</p>"},{"location":"roteiro2/main/","title":"Relat\u00f3rio","text":""},{"location":"roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro3/main/","title":"Relat\u00f3rio","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> </p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro4/limit.def/","title":"Limit.def","text":"In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom io import StringIO\n</pre> import matplotlib.pyplot as plt import numpy as np from io import StringIO In\u00a0[\u00a0]: Copied! <pre>eq = lambda x: np.exp(x)\n</pre> eq = lambda x: np.exp(x) In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(-.2, 2.1)\n</pre> x = np.linspace(-.2, 2.1) In\u00a0[\u00a0]: Copied! <pre>plt.rcParams[\"figure.figsize\"] = (15, 5)\n</pre> plt.rcParams[\"figure.figsize\"] = (15, 5) In\u00a0[\u00a0]: Copied! <pre>xa = 1.5\nya = 7\nk = 0.3\nka = xa - k\nak = xa + k\n</pre> xa = 1.5 ya = 7 k = 0.3 ka = xa - k ak = xa + k In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(1, 3)\nfor i in range(3):\n  ax[i].axhline(0, color='gray') # x = 0\n  ax[i].axvline(0, color='gray') # y = 0\n  ax[i].spines['top'].set_visible(False)\n  ax[i].spines['right'].set_visible(False)\n  ax[i].spines['bottom'].set_visible(False)\n  ax[i].spines['left'].set_visible(False)\n  ax[i].plot(x, eq(x), '-r', lw=4)\n  ax[i].set_xlim(min(x), max(x))\n  ax[i].set_xticks([])\n  ax[i].set_yticks([])\n  ax[i].plot([ka, ka], [0, eq(ka)], 'g:')\n  ax[i].plot([0, ka], [eq(ka), eq(ka)], 'g:')\n  ax[i].plot([ak, ak], [0, eq(ak)], 'g:')\n  ax[i].plot([0, ak], [eq(ak), eq(ak)], 'g:')\n  ax[i].text(xa, -0.5, 'a', horizontalalignment='center', fontsize=15)\n  ax[i].text(ka, -0.5, '$a-\\delta$', horizontalalignment='center', fontsize=15)\n  ax[i].text(ak, -0.5, '$a+\\delta$', horizontalalignment='center', fontsize=15)\n  ax[i].text(0, eq(ka), '$L-\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)\n  ax[i].text(0, eq(ak), '$L+\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)\n</pre> fig, ax = plt.subplots(1, 3) for i in range(3):   ax[i].axhline(0, color='gray') # x = 0   ax[i].axvline(0, color='gray') # y = 0   ax[i].spines['top'].set_visible(False)   ax[i].spines['right'].set_visible(False)   ax[i].spines['bottom'].set_visible(False)   ax[i].spines['left'].set_visible(False)   ax[i].plot(x, eq(x), '-r', lw=4)   ax[i].set_xlim(min(x), max(x))   ax[i].set_xticks([])   ax[i].set_yticks([])   ax[i].plot([ka, ka], [0, eq(ka)], 'g:')   ax[i].plot([0, ka], [eq(ka), eq(ka)], 'g:')   ax[i].plot([ak, ak], [0, eq(ak)], 'g:')   ax[i].plot([0, ak], [eq(ak), eq(ak)], 'g:')   ax[i].text(xa, -0.5, 'a', horizontalalignment='center', fontsize=15)   ax[i].text(ka, -0.5, '$a-\\delta$', horizontalalignment='center', fontsize=15)   ax[i].text(ak, -0.5, '$a+\\delta$', horizontalalignment='center', fontsize=15)   ax[i].text(0, eq(ka), '$L-\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)   ax[i].text(0, eq(ak), '$L+\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15) In\u00a0[\u00a0]: Copied! <pre>ax[0].plot([xa, xa], [0, eq(xa)], 'b:')\nax[0].plot([0, xa], [eq(xa), eq(xa)], 'b:')\nax[0].plot(xa, eq(xa), 'ro', ms=15)\nax[0].text(0, eq(xa), 'L=f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[1].plot([xa, xa], [0, eq(xa)], 'b:')\nax[1].plot([0, xa], [eq(xa), eq(xa)], 'm:')\nax[1].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white')\nax[1].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[2].plot(xa, eq(xa), marker='o', ms=15, mec='white', color='white')\nax[2].plot([xa, xa], [0, ya], 'b:')\nax[2].plot([0, xa], [ya, ya], 'b:')\nax[2].plot([0, xa], [eq(xa), eq(xa)], 'm:')\nax[2].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white')\nax[2].plot(xa, ya, 'ro', ms=15)\nax[2].text(0, ya, 'f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[2].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15)\n</pre> ax[0].plot([xa, xa], [0, eq(xa)], 'b:') ax[0].plot([0, xa], [eq(xa), eq(xa)], 'b:') ax[0].plot(xa, eq(xa), 'ro', ms=15) ax[0].text(0, eq(xa), 'L=f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[1].plot([xa, xa], [0, eq(xa)], 'b:') ax[1].plot([0, xa], [eq(xa), eq(xa)], 'm:') ax[1].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white') ax[1].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[2].plot(xa, eq(xa), marker='o', ms=15, mec='white', color='white') ax[2].plot([xa, xa], [0, ya], 'b:') ax[2].plot([0, xa], [ya, ya], 'b:') ax[2].plot([0, xa], [eq(xa), eq(xa)], 'm:') ax[2].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white') ax[2].plot(xa, ya, 'ro', ms=15) ax[2].text(0, ya, 'f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[2].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15) In\u00a0[\u00a0]: Copied! <pre>fig.tight_layout()\n</pre> fig.tight_layout() In\u00a0[\u00a0]: Copied! <pre>buffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</pre> buffer = StringIO() plt.savefig(buffer, format=\"svg\", transparent=True) print(buffer.getvalue())"},{"location":"roteiro4/main/","title":"Relat\u00f3rio","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-09-05T19:16:13.326462 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ 2025-09-05T19:16:14.711505 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"roteiro4/smc/","title":"Smc","text":"In\u00a0[\u00a0]: Copied! <pre>from datetime import datetime\nimport matplotlib.pyplot as plt\nimport yfinance as yf\nimport numpy as np\nimport pandas as pd\nfrom io import StringIO\n</pre> from datetime import datetime import matplotlib.pyplot as plt import yfinance as yf import numpy as np import pandas as pd from io import StringIO In\u00a0[\u00a0]: Copied! <pre>num_days = 250\nnum_simulations = 200\norder_poly = 1\n</pre> num_days = 250 num_simulations = 200 order_poly = 1 In\u00a0[\u00a0]: Copied! <pre>ticker = '^BVSP'\n</pre> ticker = '^BVSP' In\u00a0[\u00a0]: Copied! <pre>info = yf.Ticker(ticker)\ndata = info.history(period='2y')\n</pre> info = yf.Ticker(ticker) data = info.history(period='2y') In\u00a0[\u00a0]: Copied! <pre>close = data['Close']\ndaily_return = close.pct_change()\n</pre> close = data['Close'] daily_return = close.pct_change() In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(1, len(close), len(close))\nf = np.poly1d(np.polyfit(x, close, order_poly))\nxs = np.linspace(max(x), max(x) + num_days, num_days)\n</pre> x = np.linspace(1, len(close), len(close)) f = np.poly1d(np.polyfit(x, close, order_poly)) xs = np.linspace(max(x), max(x) + num_days, num_days) In\u00a0[\u00a0]: Copied! <pre>sigma = daily_return.std()\nmu = daily_return.mean()\n</pre> sigma = daily_return.std() mu = daily_return.mean() In\u00a0[\u00a0]: Copied! <pre>simulated_prices = np.zeros((num_days, num_simulations))\n</pre> simulated_prices = np.zeros((num_days, num_simulations)) In\u00a0[\u00a0]: Copied! <pre>for i in range(num_simulations):\n    simulated_prices[0][i] = close[-1]\n    for j in range(1, num_days):\n        daily_return = np.random.normal(mu, sigma)\n        simulated_prices[j][i] = simulated_prices[j-1][i] * (1 + daily_return)\n</pre> for i in range(num_simulations):     simulated_prices[0][i] = close[-1]     for j in range(1, num_days):         daily_return = np.random.normal(mu, sigma)         simulated_prices[j][i] = simulated_prices[j-1][i] * (1 + daily_return) In\u00a0[\u00a0]: Copied! <pre>simulated_means = np.mean(simulated_prices, axis=1)\nsimulated_stds = np.std(simulated_prices, axis=1)\n</pre> simulated_means = np.mean(simulated_prices, axis=1) simulated_stds = np.std(simulated_prices, axis=1) In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nax.plot(\n    x, close,\n    x, f(x), 'r:',\n    xs, simulated_prices,\n    xs, simulated_means,\n    xs, simulated_means + 1*simulated_stds, 'w:',\n    xs, simulated_means - 1*simulated_stds, 'w:',\n    xs, simulated_means + 2*simulated_stds, 'k:',\n    xs, simulated_means - 2*simulated_stds, 'k:',\n    xs, f(xs), 'g',\n)\nax.set_xlim(min(x), max(xs))\n</pre> fig, ax = plt.subplots(1, 1, figsize=(12, 8)) ax.plot(     x, close,     x, f(x), 'r:',     xs, simulated_prices,     xs, simulated_means,     xs, simulated_means + 1*simulated_stds, 'w:',     xs, simulated_means - 1*simulated_stds, 'w:',     xs, simulated_means + 2*simulated_stds, 'k:',     xs, simulated_means - 2*simulated_stds, 'k:',     xs, f(xs), 'g', ) ax.set_xlim(min(x), max(xs)) In\u00a0[\u00a0]: Copied! <pre>buffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</pre> buffer = StringIO() plt.savefig(buffer, format=\"svg\") print(buffer.getvalue())"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}