# MLP no Adult Income ‚Äî Relat√≥rio

---

## 1) Objetivo

Neste projeto, buscamos prever se a renda anual de uma pessoa √© **>50K** ou **<=50K** utilizando o conjunto **Adult Income**.  
Trata-se de um problema de **classifica√ß√£o bin√°ria** com amostra ampla (30k+ observa√ß√µes) e m√∫ltiplos atributos, majoritariamente categ√≥ricos.

- N√£o utilizamos datasets cl√°ssicos superexpostos (Titanic/Iris/Wine).
- Implementamos um **MLP em NumPy**.

---

## 2) Dataset Selection

**Nome do dataset:** *Adult Income (Census Income)*

**Fonte:** [UCI Machine Learning Repository](https://www.kaggle.com/datasets/uciml/adult-census-income)

**Tamanho utilizado:** aproximadamente **30 000 registros** ap√≥s limpeza, com cerca de **105 vari√°veis** num√©ricas/categ√≥ricas (ap√≥s codifica√ß√£o one-hot) e **1 vari√°vel-alvo** (`income`).

**Descri√ß√£o:** O Adult Census Income Dataset, tamb√©m conhecido como Census Income ou Adult dataset, foi extra√≠do do Censo norte-americano de 1994 e tem como objetivo prever se a renda anual de um indiv√≠duo ultrapassa US$ 50.000, com base em vari√°veis demogr√°ficas e profissionais. Trata-se de um problema cl√°ssico de classifica√ß√£o bin√°ria, amplamente utilizado para avaliar m√©todos de pr√©-processamento, tratamento de desbalanceamento e modelagem supervisionada em aprendizado de m√°quina.

**Motiva√ß√£o da escolha:** √© um problema **realista e amplamente estudado** em aprendizado de m√°quina, √∫til para explorar t√©cnicas de **classifica√ß√£o supervisionada**, **tratamento de desbalanceamento**, e **engenharia de vari√°veis categ√≥ricas**. Al√©m disso, sua **complexidade moderada** (n√∫mero alto de atributos ap√≥s codifica√ß√£o) e **desbalanceamento entre classes** tornam o dataset adequado para avaliar m√©tricas al√©m da acur√°cia, alem de aplicarmos os conhecimentos adquiridos na disciplina.


---

## 3) Dataset Explanation

Todas as exploracoes e processos feitos nesse data set esta no arquivo : (https://github.com/marinnagc/classification_mlp_mng/blob/main/exploracao.ipynb)

### 3.1) Descriptive Statistics

As vari√°veis num√©ricas apresentam escalas e distribui√ß√µes bastante distintas. A m√©dia de idade √© de aproximadamente 38,6 anos, com desvio padr√£o de 13,6, indicando uma amostra adulta heterog√™nea. A jornada m√©dia semanal √© de 40 horas, coerente com o padr√£o de tempo integral.
A vari√°vel education.num tem m√©dia 10, correspondente a um n√≠vel educacional m√©dio entre Some College e Bachelors.
Os atributos capital-gain e capital-loss s√£o altamente assim√©tricos, com a maior parte dos valores igual a zero ‚Äî o que indica que apenas uma pequena fra√ß√£o da popula√ß√£o declarou ganhos ou perdas de capital relevantes.

| Vari√°vel       | M√©dia   | Desvio padr√£o | M√≠nimo | M√°ximo    |
| -------------- | ------- | ------------- | ------ | --------- |
| age            | 38.6    | 13.6          | 17     | 90        |
| hours.per.week | 40.4    | 12.3          | 1      | 99        |
| education.num  | 10.1    | 2.6           | 1      | 16        |
| capital.gain   | 1077.6  | 7385.3        | 0      | 99999     |
| capital.loss   | 87.3    | 403.0         | 0      | 4356      |
| fnlwgt         | 189,778 | 105,550       | 12,285 | 1,484,705 |


### 3.2)  Target Distribution

A vari√°vel-alvo (income) √© desbalanceada, com cerca de 75% dos indiv√≠duos recebendo at√© US$ 50K e 25% acima desse valor.
Isso sugere a necessidade de m√©tricas de avalia√ß√£o al√©m da acur√°cia, como F1-score, ROC AUC e Precision‚ÄìRecall AUC.

![Target_dist](targ_dist.png)

### 3.3)  Categorical Variables


Ao analisar as variaveis categoricas, a maior parte dos indiv√≠duos pertence √† classe de trabalho ‚ÄúPrivate‚Äù, seguida de trabalhadores aut√¥nomos (Self-emp-not-inc e Self-emp-inc) e servidores p√∫blicos (Local-gov e State-gov).


Em termos de ocupa√ß√£o, destacam-se ‚ÄúProf-specialty‚Äù, ‚ÄúCraft-repair‚Äù e ‚ÄúExec-managerial‚Äù, representando setores de maior qualifica√ß√£o.
A esmagadora maioria dos registros refere-se a pessoas nascidas nos Estados Unidos, com poucos exemplos de outros pa√≠ses.

Podemos prover isso com o grafico abaixo:


![categorical_distribution](categorical_distributions_combined.png)


### 3.4)  Correlation Matrix

O heatmap de correla√ß√£o mostra que n√£o h√° rela√ß√µes lineares fortes entre as vari√°veis num√©ricas.
A maior correla√ß√£o observada √© entre education.num e hours.per.week (r ‚âà 0.15), ainda assim bastante baixa.
Isso sugere que cada atributo contribui de forma relativamente independente para o modelo, o que pode favorecer m√©todos que capturam intera√ß√µes n√£o lineares (como √°rvores de decis√£o e ensemble models).

![alt text](correlation.png)


## 4) Data Cleaning and Normalization

Esse processo foi feito em :(https://github.com/marinnagc/classification_mlp_mng/blob/main/limpeza.ipynb)

Durante a etapa de limpeza, substitu√≠mos todos os valores representados por ‚Äú?‚Äù por None e preenchemos os valores ausentes com a moda de cada coluna (valor mais frequente).
Essa estrat√©gia preserva a distribui√ß√£o original dos dados e evita distor√ß√µes que poderiam surgir com imputa√ß√µes baseadas em m√©dia ou mediana.

Na normaliza√ß√£o, aplicamos o Z-score √†s vari√°veis num√©ricas, de forma que cada atributo passou a ter m√©dia 0 e desvio padr√£o 1, garantindo uma escala uniforme entre vari√°veis como age, hours-per-week e capital-gain.


Before ‚Üí After

| age | workclass | capital.gain | hours.per.week |
| --- | --------- | ------------ | -------------- |
| 39  | ?         | 0            | 40             |
| 50  | Private   | 7688         | 60             |
| 28  | ?         | 0            | 40             |

Ap√≥s limpeza e normaliza√ß√£o:

| age (z) | workclass | capital.gain (z) | hours.per.week (z) |
| ------- | --------- | ---------------- | ------------------ |
| -0.10   | Private   | -0.12            | -0.04              |
| 0.85    | Private   | 1.75             | 1.53               |
| -1.05   | Private   | -0.12            | -0.04              |



## 5) MLP Implementation


Neste projeto, foram utilizadas duas implementa√ß√µes de **MLP (Perceptron Multicamadas)**:
uma com a biblioteca **scikit-learn**, para refer√™ncia e benchmarking,
e outra **implementada manualmente em NumPy**, para demonstrar os princ√≠pios de *forward pass*, *backpropagation* e *early stopping*.

### üîπ MLP com scikit-learn

```python
# mlp_biblio.py
import numpy as np
from sklearn.neural_network import MLPClassifier

class SklearnMLPModel:
    """MLP com scikit-learn: interface comum .fit(), .predict_proba(), .predict(), .loss_curve()."""
    def __init__(self,
                 hidden_layer_sizes=(64,),
                 lr=1e-3,
                 alpha=1e-4,
                 batch_size=128,
                 max_iter=100,
                 early_stopping=True,
                 random_state=42):
        self.clf = MLPClassifier(
            hidden_layer_sizes=hidden_layer_sizes,
            activation="relu",
            solver="adam",
            learning_rate_init=lr,
            batch_size=batch_size,
            max_iter=max_iter,
            alpha=alpha,             # Regulariza√ß√£o L2
            early_stopping=early_stopping,
            n_iter_no_change=10,
            random_state=random_state
        )
        self.fitted_ = False

    def fit(self, X_tr, y_tr):
        self.clf.fit(X_tr, y_tr)
        self.fitted_ = True
        return self

    def predict_proba(self, X):
        assert self.fitted_, "Treine o modelo antes de prever."
        return self.clf.predict_proba(X)[:, 1]

    def predict(self, X, thr=0.5):
        proba = self.predict_proba(X)
        return (proba >= thr).astype(int)

    def loss_curve(self):
        return getattr(self.clf, "loss_curve_", None)
```

**Principais hiperpar√¢metros:**

* `hidden_layer_sizes`: define o n√∫mero de neur√¥nios por camada oculta (ex.: `(64,)` ‚Üí 1 camada com 64 unidades).
* `lr` (`learning_rate_init`): taxa de aprendizado usada pelo otimizador *Adam*. Controla o tamanho do passo nas atualiza√ß√µes de peso.
* `alpha`: termo de regulariza√ß√£o L2 (*weight decay*), que ajuda a evitar *overfitting*.
* `batch_size`: tamanho do mini-lote durante o treinamento (padr√£o = 128).
* `max_iter`: n√∫mero m√°ximo de √©pocas (itera√ß√µes completas sobre o conjunto de treino).
* `early_stopping`: interrompe o treinamento se n√£o houver melhora na valida√ß√£o por v√°rias √©pocas.
* `random_state`: semente para reprodutibilidade dos resultados.

---

### üîπ MLP implementado manualmente (NumPy)

```python
# mlp_manual.py
import numpy as np

def _sigmoid(z): return 1 / (1 + np.exp(-z))
def _relu(z): return np.maximum(0, z)
def _relu_grad(z): return (z > 0).astype(z.dtype)

def _bce_loss(y_true, y_pred, eps=1e-12):
    y_pred = np.clip(y_pred, eps, 1 - eps)
    return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))

class _MLPBinary:
    """MLP de uma camada oculta: ReLU ‚Üí Sigmoid, perda BCE, SGD mini-batch, L2 e early-stopping."""
    def __init__(self, n_in, n_hidden=64, lr=1e-3, l2=1e-4, seed=42):
        rng = np.random.default_rng(seed)
        # Inicializa√ß√£o He para W1 (ReLU) e Xavier para W2
        self.W1 = rng.normal(0, np.sqrt(2.0/n_in), size=(n_in, n_hidden))
        self.b1 = np.zeros((n_hidden,))
        self.W2 = rng.normal(0, np.sqrt(1.0/n_hidden), size=(n_hidden, 1))
        self.b2 = np.zeros((1,))
        self.lr, self.l2 = lr, l2

    def forward(self, X):
        z1 = X @ self.W1 + self.b1
        a1 = _relu(z1)
        z2 = a1 @ self.W2 + self.b2
        yhat = _sigmoid(z2).ravel()
        return yhat, (X, z1, a1, z2, yhat)

    def backward(self, cache, y_true):
        X, z1, a1, z2, yhat = cache
        N = X.shape[0]
        y_true = y_true.reshape(-1, 1)
        yhat = yhat.reshape(-1, 1)

        dz2 = (yhat - y_true) / N
        dW2 = a1.T @ dz2 + self.l2 * self.W2
        db2 = dz2.sum(axis=0)

        da1 = dz2 @ self.W2.T
        dz1 = da1 * _relu_grad(z1)
        dW1 = X.T @ dz1 + self.l2 * self.W1
        db1 = dz1.sum(axis=0)

        # Atualiza√ß√£o dos pesos
        self.W2 -= self.lr * dW2
        self.b2 -= self.lr * db2
        self.W1 -= self.lr * dW1
        self.b1 -= self.lr * db1

    def predict_proba(self, X):
        yhat, _ = self.forward(X)
        return yhat
```

---

**Principais hiperpar√¢metros:**

* `n_hidden`: n√∫mero de neur√¥nios na camada oculta (capacidade do modelo).
* `lr`: *learning rate* (taxa de aprendizado); controla o qu√£o r√°pido os pesos s√£o atualizados.
* `l2`: coeficiente de regulariza√ß√£o L2 (penaliza pesos grandes, reduz *overfitting*).
* `batch_size`: tamanho dos mini-lotes de dados usados em cada atualiza√ß√£o.
* `epochs`: n√∫mero m√°ximo de √©pocas de treinamento.
* `patience`: n√∫mero de √©pocas sem melhora antes do *early stopping*.
* `seed`: semente para reprodutibilidade.

---

### üîπ Aplicacao:

Utilizamos esse dois arquivos nesse jupyter: (https://github.com/marinnagc/classification_mlp_mng/blob/main/main.ipynb)


---
## 6)  Training and Testing Strategy

Os dados foram divididos em **70% para treino**, **15% para valida√ß√£o** e **15% para teste**, garantindo **estratifica√ß√£o da vari√°vel-alvo (`income`)** para manter a propor√ß√£o entre as classes nas tr√™s parti√ß√µes.
Essa separa√ß√£o permite usar o conjunto de valida√ß√£o para ajuste de hiperpar√¢metros (como n√∫mero de neur√¥nios, taxa de aprendizado, regulariza√ß√£o) e o conjunto de teste apenas para avalia√ß√£o final.

```python
# Divis√£o 70/15/15 estratificada e normaliza√ß√£o/one-hot
y = (df["income"].astype(str) == ">50K").astype(int)
X = df.drop(columns=["income"])

X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y, test_size=0.15, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val
)

prep = Preprocessor(NUM_COLS, CAT_COLS)
X_train_proc = prep.fit_transform(X_train)
X_val_proc   = prep.transform(X_val)
X_test_proc  = prep.transform(X_test)
```

###  üîπ Treinamento

O modelo foi treinado com **mini-batches de 128 amostras**, equilibrando **velocidade de converg√™ncia** e **estabilidade num√©rica** ‚Äî mais eficiente que o treinamento *batch* completo (que √© mais lento) e menos ruidoso que o *online* (stochastic).


```python
# Treinando e avaliar o MLP (scikit-learn)
from mlp import SklearnMLPModel
from sklearn.metrics import classification_report, roc_auc_score, average_precision_score

skl = SklearnMLPModel(hidden_layer_sizes=(64,), lr=1e-3, alpha=1e-4,
                      batch_size=128, max_iter=100, early_stopping=True, random_state=42)

skl.fit(X_train_proc, y_train)

y_val_pred = skl.predict(X_val_proc)
y_test_pred = skl.predict(X_test_proc)
y_test_proba = skl.predict_proba(X_test_proc)

print("ROC-AUC (test):", roc_auc_score(y_test, y_test_proba))
print("AP (PR AUC, test):", average_precision_score(y_test, y_test_proba))
print(classification_report(y_test, y_test_pred))
```

Alem disso, fizemos o mesmo para NumPy tambem:

```python

#Treinando e avaliando o MLP (agora com Numpy)

from mlp_manual import NumpyMLPModel
from sklearn.metrics import (
    classification_report, roc_auc_score, average_precision_score,
    ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay
)
import matplotlib.pyplot as plt

# ===== Treino =====
npmlp = NumpyMLPModel(n_hidden=64, lr=1e-3, l2=1e-4, batch_size=128, epochs=80, patience=8, seed=42)
npmlp.fit(X_train_proc, y_train_np, X_val_proc, y_val_np)

# ===== Predi√ß√µes TEST =====
y_test_proba_np = npmlp.predict_proba(X_test_proc)
y_test_pred_np  = npmlp.predict(X_test_proc)

# ===== Predi√ß√µes TRAIN =====
y_train_proba_np = npmlp.predict_proba(X_train_proc)
y_train_pred_np  = (y_train_proba_np >= 0.5).astype(int)

```

Sendo assim, tivemos como resultado:

### üîπ Estrat√©gias contra overfitting

* **Early stopping:** interrompe o treino ao detectar estagna√ß√£o na valida√ß√£o.
* **Regulariza√ß√£o L2 (`alpha=1e-4`):** reduz magnitudes dos pesos.
* **Valida√ß√£o separada (15%)**: usada apenas para monitorar desempenho e ajustar hiperpar√¢metros.
* **Random seed (`random_state=42`):** garante reprodutibilidade dos resultados.

---

**Resumo da configura√ß√£o:**

| Par√¢metro        | Valor    | Descri√ß√£o                                  |
| ---------------- | -------- | ------------------------------------------ |
| Split            | 70/15/15 | treino / valida√ß√£o / teste (estratificado) |
| Batch size       | 128      | mini-batch SGD                             |
| Learning rate    | 1e-3     | inicial do otimizador Adam                 |
| Regulariza√ß√£o L2 | 1e-4     | evita overfitting                          |
| Early stopping   | Sim      | paci√™ncia de 10 √©pocas                     |
| Random seed      | 42       | reprodutibilidade                          |




## 7) Error Curves and Visualization

Com os metodos adotados, tivemos como resultado:


![Numpy_Error](numpy_loss_acc_side_by_side.png)


A loss diminui rapidamente nas primeiras √©pocas e se estabiliza ap√≥s ~50, indicando converg√™ncia.
A acur√°cia cresce de forma cont√≠nua at√© cerca de 0.83, com curvas de treino e valida√ß√£o pr√≥ximas ‚Äî mostrando boa generaliza√ß√£o e sem sinais de overfitting.



### Leitura


-> As curvas tendem a apresentar queda acentuada nas primeiras √©pocas e estabiliza√ß√£o posterior.  

-> Um distanciamento significativo entre treino e valida√ß√£o indica sobreajuste.


---

## 8)  Evaluation Metrics

Nesta se√ß√£o, s√£o apresentados os resultados quantitativos e visuais obtidos na classifica√ß√£o da vari√°vel-alvo `income` (>50K vs <=50K), comparando o **modelo baseline** com os dois **modelos MLP** (NumPy e Scikit-learn).

---

### Baseline ( prev√™ `<=50K`)

O baseline serve como ponto de refer√™ncia, representando um classificador que sempre escolhe a classe majorit√°ria.

<p align="center">
  <img src="conf_matrix_baseline.png" alt="Confusion Matrix ‚Äì Baseline" width="40%"/>
  <img src="roc_curve_baseline.png" alt="ROC ‚Äì Baseline" width="35%"/>
</p>

```
               precision    recall  f1-score   support

           0      0.759     1.000     0.863      3709
           1      0.000     0.000     0.000      1176

    accuracy                          0.759      4885
   macro avg      0.380     0.500     0.432      4885
weighted avg      0.576     0.759     0.655      4885
```

**Interpreta√ß√£o:**
O baseline atinge **acur√°cia de 0.76**, mas isso se deve apenas ao **desbalanceamento de classes** (a maioria pertence a `<=50K`).
Ele **n√£o consegue identificar nenhum exemplo da classe >50K**, resultando em **precis√£o, recall e F1 = 0** para a classe positiva e **AUC = 0.50** (equivalente a um classificador aleat√≥rio).

---

### Modelos MLP ‚Äî Resultados no Conjunto de Teste

| Modelo                 | Accuracy | Precision | Recall | F1    | ROC-AUC |
| ---------------------- | -------- | --------- | ------ | ----- | ------- |
| **MLP Manual (NumPy)** | 0.843    | 0.723     | 0.561  | 0.632 | 0.889   |
| **MLP Scikit-Learn**   | 0.858    | 0.741     | 0.632  | 0.682 | 0.908   |

---

### Visualiza√ß√µes de Desempenho

<p align="center">
  <img src="roc_curve_test.png" alt="Precision‚ÄìRecall and ROC ‚Äì Scikit-learn" width="40%"/>
</p>

**Observa√ß√µes:**

* A **curva ROC (AUC ‚âà 0.91)** indica **forte capacidade de separa√ß√£o** entre as duas classes.
* A **curva Precision‚ÄìRecall (AP ‚âà 0.78)** √© mais informativa em dados desbalanceados: o modelo mant√©m **alta precis√£o at√© ~0.6 de recall**.
* As **matrizes de confus√£o** (n√£o mostradas aqui em detalhe) revelam que os erros se concentram em falsos negativos (classe >50K prevista como <=50K), refletindo o desbalanceamento do dataset.

---

### Compara√ß√£o Geral

<p align="center">
  <img src="comparacao_modelos_metricas.png" alt="Compara√ß√£o de m√©tricas ‚Äì Baseline vs MLPs" width="60%"/>
</p>

**An√°lise:**

* Ambos os MLPs superam o baseline em todas as m√©tricas, com ganhos significativos em **precis√£o**, **recall**, **F1** e **AUC**.
* O **MLP Scikit-Learn** apresentou desempenho ligeiramente superior, com **melhor recall (+0.07)** e **F1 (+0.05)**, indicando **maior equil√≠brio** entre as classes.
* O **MLP Manual (NumPy)** obteve resultados muito pr√≥ximos, validando a implementa√ß√£o e o processo de otimiza√ß√£o.
* O **recall ainda moderado** na classe positiva (>50K) reflete o impacto do desbalanceamento ‚Äî um ponto que poderia ser melhorado com **ajuste de threshold** ou **t√©cnicas de reamostragem (SMOTE, class weights)**.

  
---

## 9) Conclusions

- O MLP superou o **baseline** de 0,75, alcan√ßando cerca de **0,84** de acur√°cia em teste, com **F1** competitivo.  
- Em dados desbalanceados, **F1** e **PR-AUC** complementam a leitura de **accuracy**.  
- O ajuste de **threshold** permite calibrar o compromisso **precis√£o vs. recall** conforme o custo de FP/FN.  
- Possibilidades de avan√ßo incluem **pesos por classe** na BCE, **tuning** (n√∫mero de camadas/neur√¥nios, `lr`, `l2`), **agrupamento de categorias raras** (e.g., `native-country`) e, em bibliotecas, **dropout** e **batch normalization**.

---

## 10)  Reprodutibilidade

1. Geramos **`adult_clean.csv`** (pipeline de prepara√ß√£o descrito na Se√ß√£o 3).  
2. Realizamos **split estratificado** (70/15/15).  
3. Recalculamos o **z-score** com estat√≠sticas do **treino** e aplicamos em valida√ß√£o e teste.  
4. Treinamos o MLP (NumPy) com **early stopping** e salvamos o melhor estado.  
5. Registramos hist√≥rico (CSV) e figuras (loss/acc, ROC/PR).  
6. Reportamos as m√©tricas finais de **teste**.

