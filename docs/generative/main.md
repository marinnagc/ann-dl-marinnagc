# Projeto: Modelos Generativos com Stable Diffusion

> **Disciplina:** Artificial Neural Networks and Deep Learning  
> **InstituiÃ§Ã£o:** Insper  
> **PerÃ­odo:** 2025.2  
> **Alunos:** Guilherme Paraiso, Nicholas Balkins e Marinna Cesar
 
---

## Sobre o Projeto

Este projeto explora **modelos generativos** usando **Stable Diffusion v1.5** atravÃ©s da plataforma ComfyUI. Implementamos diferentes pipelines de geraÃ§Ã£o e transformaÃ§Ã£o de imagens, analisando a arquitetura dos modelos de difusÃ£o latente e seus componentes fundamentais.

**Objetivo:** Compreender e aplicar tÃ©cnicas de geraÃ§Ã£o de imagens usando modelos de difusÃ£o, explorando diferentes configuraÃ§Ãµes e arquiteturas.

---

## Workflows Implementados

Este projeto implementa trÃªs workflows de complexidade crescente, demonstrando progressÃ£o no domÃ­nio de modelos generativos:

### Conceito C: Text-to-Image (GeraÃ§Ã£o BÃ¡sica)

GeraÃ§Ã£o de imagens de paisagens montanhosas a partir de descriÃ§Ãµes textuais usando apenas o modelo base Stable Diffusion v1.5.

#### Diagrama do Workflow no ComfyUI

![Workflow Text-to-Image](outputs/C_ComfyUI.png)
*Diagrama do workflow Text-to-Image implementado no ComfyUI. A imagem pode parecer embaÃ§ada aqui devido Ã  alta resoluÃ§Ã£o - abra em nova aba ou faÃ§a download para visualizar com clareza.*

#### Arquitetura do Pipeline

```mermaid
graph TD
    A[Prompt de Texto] -->|TokenizaÃ§Ã£o| B[CLIP Text Encoder]
    B -->|Embeddings 768D| C[Conditioning]
    D[Empty Latent Image<br/>64Ã—64Ã—4] -->|RuÃ­do AleatÃ³rio 100%| E[KSampler]
    C -->|Guia SemÃ¢ntico| E
    F[Checkpoint SD v1.5<br/>4.26 GB] -->|U-Net Weights| E
    E -->|25 Steps de Denoising| G[Latent Limpo<br/>64Ã—64Ã—4]
    G --> H[VAE Decoder]
    H -->|Upscale 8x| I[Imagem RGB<br/>512Ã—512Ã—3]
    I --> J[Save Image]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style E fill:#ffe1e1
    style H fill:#e1ffe1
    style I fill:#f0e1ff
```


#### Componentes Utilizados

| Componente | FunÃ§Ã£o | Entrada | SaÃ­da |
|------------|--------|---------|-------|
| **CLIP Text Encoder** | Converte texto em representaÃ§Ã£o numÃ©rica | String de texto | Tensor 768D |
| **Empty Latent Image** | Cria tensor de ruÃ­do inicial | DimensÃµes (512Ã—512) | Latent (64Ã—64Ã—4) |
| **U-Net** | Remove ruÃ­do iterativamente condicionado pelo prompt | Latent + Embeddings | Latent limpo |
| **KSampler** | Controla processo de amostragem (steps, cfg, seed) | ConfiguraÃ§Ãµes | SequÃªncia de latents |
| **VAE Decoder** | Converte latent para espaÃ§o RGB | Latent (64Ã—64Ã—4) | Imagem (512Ã—512Ã—3) |

#### Experimentos Realizados

**Prompt Base:**
```
beautiful sunset over mountains, dramatic clouds, golden hour lighting, 
highly detailed, 8k, photorealistic, landscape photography
```

**Negative Prompt:**
```
ugly, blurry, low quality, cartoon, anime, distorted
```
- Melhoria significativa na qualidade sem retreinar modelo
- Controle fino atravÃ©s dos parÃ¢metros de strength
- ReutilizÃ¡vel em diferentes prompts
- CombinÃ¡vel com outros LoRAs

**Trade-offs:**
- Adiciona ~1-2 segundos ao tempo de geraÃ§Ã£o
- Requer download e gerenciamento de arquivos LoRA
- Strength muito alto (>0.9) pode causar overfitting ao estilo
- Nem todos os LoRAs sÃ£o compatÃ­veis com SD v1.5

**AplicaÃ§Ãµes PrÃ¡ticas:**
- **Arte Conceitual:** Criar paisagens para jogos/filmes
- **ReferÃªncias Visuais:** IlustraÃ§Ã£o de cenÃ¡rios especÃ­ficos
- **ExploraÃ§Ã£o Criativa:** Testar diferentes estilos rapidamente
- **ProduÃ§Ã£o em Massa:** Gerar mÃºltiplas variaÃ§Ãµes consistentes

**Workflow JSON:** [Conceito A.json](workflows/Conceito%20A.json)

---

### Conceito B: Image-to-Image (TransformaÃ§Ã£o)

TransformaÃ§Ã£o de imagens existentes atravÃ©s de controle de intensidade com parÃ¢metro **denoise**, expandindo as capacidades do Conceito C.

#### Diagrama do Workflow no ComfyUI

![Workflow Image-to-Image](outputs/B_ComfyUI.png)
*Diagrama do workflow Image-to-Image implementado no ComfyUI. Note os nÃ³s adicionais: Load Image e VAE Encode. A imagem pode parecer embaÃ§ada aqui devido Ã  alta resoluÃ§Ã£o - abra em nova aba ou faÃ§a download para visualizar com clareza.*

#### Arquitetura do Pipeline

```mermaid
graph TD
    A[Prompt de Texto] -->|TokenizaÃ§Ã£o| B[CLIP Text Encoder]
    B -->|Embeddings 768D| C[Conditioning]
    D[Empty Latent Image<br/>64Ã—64Ã—4] -->|RuÃ­do AleatÃ³rio 100%| E[KSampler]
    C -->|Guia SemÃ¢ntico| E
    F[Checkpoint SD v1.5<br/>4.26 GB] -->|U-Net Weights| E
    E -->|25 Steps de Denoising| G[Latent Limpo<br/>64Ã—64Ã—4]
    G --> H[VAE Decoder]
    H -->|Upscale 8x| I[Imagem RGB<br/>512Ã—512Ã—3]
    I --> J[Save Image]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style E fill:#ffe1e1
    style H fill:#e1ffe1
    style I fill:#f0e1ff
```

#### Componentes Utilizados

| Componente | FunÃ§Ã£o | Entrada | SaÃ­da |
|------------|--------|---------|-------|
| **CLIP Text Encoder** | Converte texto em representaÃ§Ã£o numÃ©rica | String de texto | Tensor 768D |
| **Empty Latent Image** | Cria tensor de ruÃ­do inicial | DimensÃµes (512Ã—512) | Latent (64Ã—64Ã—4) |
| **U-Net** | Remove ruÃ­do iterativamente condicionado pelo prompt | Latent + Embeddings | Latent limpo |
| **KSampler** | Controla processo de amostragem (steps, cfg, seed) | ConfiguraÃ§Ãµes | SequÃªncia de latents |
| **VAE Decoder** | Converte latent para espaÃ§o RGB | Latent (64Ã—64Ã—4) | Imagem (512Ã—512Ã—3) |

#### Experimentos Realizados

**Prompt Base:**
```
beautiful sunset over mountains, dramatic clouds, golden hour lighting, 
highly detailed, 8k, photorealistic, landscape photography
```

**Negative Prompt:**
```
ugly, blurry, low quality, cartoon, anime, distorted
```

##### Teste 1: Baseline (ConfiguraÃ§Ã£o PadrÃ£o)
- **Seed:** 123
- **Steps:** 20
- **CFG Scale:** 8.0
- **Sampler:** dpmpp_2m
- **Resultado:** Imagem base de referÃªncia

![Baseline](outputs/conceitoC_baseline.png)

##### Teste 2: VariaÃ§Ã£o de Seed
- **Seed:** 456 â† **MUDANÃ‡A**
- **Steps:** 20
- **CFG Scale:** 8.0
- **Sampler:** dpmpp_2m
- **AnÃ¡lise:** ComposiÃ§Ã£o diferente mantendo estilo similar

![Seed 456](outputs/conceitoC_seed_456.png)

##### Teste 3: CFG Scale Alto
- **Seed:** 123
- **Steps:** 20
- **CFG Scale:** 12.0 â† **MUDANÃ‡A**
- **Sampler:** dpmpp_2m
- **AnÃ¡lise:** Maior aderÃªncia ao prompt, cores mais saturadas

![CFG 12](outputs/conceitoC_cfg_12.png)

##### Teste 4: Steps Aumentados
- **Seed:** 123
- **Steps:** 50 â† **MUDANÃ‡A**
- **CFG Scale:** 8.0
- **Sampler:** dpmpp_2m
- **AnÃ¡lise:** Maior refinamento e detalhes

![Steps 50](outputs/conceitoC_steps50.png)

##### Teste 5: Sampler Diferente
- **Seed:** 123
- **Steps:** 20
- **CFG Scale:** 8.0
- **Sampler:** euler_ancestral â† **MUDANÃ‡A**
- **AnÃ¡lise:** VariaÃ§Ã£o estocÃ¡stica, resultado mais imprevisÃ­vel

![Euler Ancestral](outputs/conceitoC_euler_ancestral.png)

#### AnÃ¡lise de Resultados - Conceito C

**Impacto do Seed:**
- Controla aleatoriedade inicial
- Mesmos parÃ¢metros, seed diferente = composiÃ§Ã£o totalmente diferente
- Ãštil para gerar variaÃ§Ãµes

**Impacto do CFG Scale:**
- CFG 8.5: EquilÃ­brio entre criatividade e aderÃªncia
- CFG 12.0: Seguiu prompt mais rigidamente, cores mais intensas
- Trade-off: muito alto pode perder naturalidade

**Impacto dos Steps:**
- 25 steps: Qualidade boa, tempo razoÃ¡vel
- 50 steps: Refinamento marginal, dobro do tempo
- Retorno diminuÃ­do apÃ³s 30 steps

**Impacto do Sampler:**
- dpmpp_2m: Consistente, boa qualidade
- euler_ancestral: Mais variaÃ§Ã£o, menos previsÃ­vel
- Cada sampler tem caracterÃ­sticas prÃ³prias

**Workflow JSON:** [Conceito C (1).json](workflows/Conceito%20C%20(1).json)

---

### Conceito B: Image-to-Image (TransformaÃ§Ã£o)

TransformaÃ§Ã£o de imagens existentes atravÃ©s de controle de intensidade com parÃ¢metro **denoise**.

#### Diagrama do Workflow no ComfyUI

![Workflow Image-to-Image](outputs/B_ComfyUI.png)
*Diagrama do workflow Image-to-Image implementado no ComfyUI. Note os nÃ³s adicionais: Load Image e VAE Encode. A imagem pode parecer embaÃ§ada aqui devido Ã  alta resoluÃ§Ã£o - abra em nova aba ou faÃ§a download para visualizar com clareza.*

#### Arquitetura do Pipeline

```mermaid
graph TD
    A[Imagem Base<br/>512Ã—512Ã—3] -->|Load Image| B[VAE Encoder]
    B -->|Downscale 8x| C[Latent Original<br/>64Ã—64Ã—4]
    C -->|Adiciona RuÃ­do<br/>baseado em denoise| D[Latent com RuÃ­do]
    
    E[Prompt de Texto] -->|TokenizaÃ§Ã£o| F[CLIP Text Encoder]
    F -->|Embeddings 768D| G[Conditioning]
    
    D --> H[KSampler]
    G -->|Guia SemÃ¢ntico| H
    I[Checkpoint SD v1.5] -->|U-Net Weights| H
    
    H -->|25 Steps<br/>Denoising Parcial| J[Latent Transformado<br/>64Ã—64Ã—4]
    J --> K[VAE Decoder]
    K -->|Upscale 8x| L[Imagem Transformada<br/>512Ã—512Ã—3]
    L --> M[Save Image]
    
```

#### DiferenÃ§as do Text-to-Image

| Aspecto | Text-to-Image | Image-to-Image |
|---------|--------------|----------------|
| **Entrada** | RuÃ­do aleatÃ³rio (100%) | Imagem + ruÃ­do parcial |
| **VAE** | Apenas Decoder | Encoder + Decoder |
| **Denoise** | 1.0 (cria do zero) | 0.3-0.8 (preserva estrutura) |
| **Controle** | Apenas prompt | Prompt + imagem base |
| **Uso** | CriaÃ§Ã£o original | ModificaÃ§Ã£o/estilo |

#### Componentes Adicionais

| Componente | FunÃ§Ã£o | Entrada | SaÃ­da |
|------------|--------|---------|-------|
| **Load Image** | Carrega imagem de referÃªncia | Arquivo PNG/JPG | Tensor RGB |
| **VAE Encoder** | Converte imagem para latent space | Imagem (512Ã—512Ã—3) | Latent (64Ã—64Ã—4) |
| **Denoise Control** | Define quanto preservar vs. modificar | Valor 0.0-1.0 | Mix de latents |

#### O Papel do Denoise

O parÃ¢metro **denoise** controla a proporÃ§Ã£o entre preservaÃ§Ã£o e transformaÃ§Ã£o:

**Denoise = 0.3** (70% original preserved)
```
Original Latent â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ (80%)
Noise/Transform â–‘â–‘â–‘â–‘ (20%)
â†’ ModificaÃ§Ã£o SUTIL (ajustes leves)
```

**Denoise = 0.5** (50% original preserved)
```
Original Latent â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (50%)
Noise/Transform â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (50%)
â†’ ModificaÃ§Ã£o MODERADA (mudanÃ§as visÃ­veis)
```

**Denoise = 0.75** (30% original preserved)
```
Original Latent â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (25%)
Noise/Transform â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ (75%)
â†’ ModificaÃ§Ã£o INTENSA (transf. grande)
```

#### Imagem Base Utilizada

![Base Photo](outputs/base_photo.jpg)

*Foto base: Paisagem montanhosa ao pÃ´r do sol*

#### Experimentos Realizados

**Prompt de TransformaÃ§Ã£o:**
```
beautiful sunset over mountains, dramatic clouds, golden hour lighting, 
highly detailed, 8k, photorealistic, landscape photography
```

**ConfiguraÃ§Ãµes Fixas:**
- Seed: 123
- Steps: 20
- CFG Scale: 8.0
- Sampler: euler

##### Teste 1: Denoise 0.30 (ModificaÃ§Ã£o Sutil)
- **Denoise:** 0.30
- **Expectativa:** Preservar a maior parte da estrutura original, aplicar ajustes leves
- **Resultado:** Imagem muito prÃ³xima da original com refinamentos sutis

![Denoise 0.30](outputs/conceitoB_denoise_30.png)

**AnÃ¡lise:**
Com denoise 0.30, a transformaÃ§Ã£o Ã© mÃ­nima:
- 70% da estrutura original preservada
- 30% de transformaÃ§Ã£o baseada no prompt
- ComposiÃ§Ã£o quase idÃªntica Ã  imagem base
- Ajustes sutis em iluminaÃ§Ã£o e cores
- Ideal para refinamento e correÃ§Ãµes leves

##### Teste 2: Denoise 0.50 (ModificaÃ§Ã£o Moderada)
- **Denoise:** 0.50
- **Expectativa:** EquilÃ­brio entre preservaÃ§Ã£o e modificaÃ§Ã£o
- **Resultado:** ComposiÃ§Ã£o base mantida com melhorias significativas em cores e detalhes

![Denoise 0.50](outputs/conceitoB_baseline.png)

**AnÃ¡lise:**
Com denoise 0.50, o modelo consegue um equilÃ­brio ideal:
- 50% da estrutura original preservada
- 50% de transformaÃ§Ã£o baseada no prompt
- MantÃ©m a composiÃ§Ã£o geral da imagem
- Adiciona detalhes e refina a qualidade
- Cores e iluminaÃ§Ã£o podem mudar significativamente

##### Teste 3: Denoise 0.75 (TransformaÃ§Ã£o Intensa)
- **Denoise:** 0.75
- **Expectativa:** TransformaÃ§Ã£o significativa mantendo tema geral
- **Resultado:** MudanÃ§as dramÃ¡ticas na imagem com estrutura bÃ¡sica reconhecÃ­vel

![Denoise 0.75](outputs/conceitoB_denoise_75.png)

**AnÃ¡lise:**
Com denoise 0.75, a transformaÃ§Ã£o Ã© agressiva:
- 25% da estrutura original preservada
- 75% de transformaÃ§Ã£o baseada no prompt
- ComposiÃ§Ã£o pode mudar consideravelmente
- Elementos principais reconhecÃ­veis mas reinterpretados
- MÃ¡xima criatividade mantendo conexÃ£o com a base

#### AnÃ¡lise de Resultados - Conceito B

**ComparaÃ§Ã£o entre NÃ­veis de Denoise:**

| Denoise | PreservaÃ§Ã£o | TransformaÃ§Ã£o | Uso Ideal |
|---------|-------------|---------------|-----------|
| **0.30** | 70% | 30% | Refinamento, correÃ§Ãµes sutis |
| **0.50** | 50% | 50% | EquilÃ­brio, melhorias visÃ­veis |
| **0.75** | 25% | 75% | ReimaginaÃ§Ã£o, mudanÃ§as dramÃ¡ticas |

**ObservaÃ§Ãµes:**
- Denoise baixo (0.3): MantÃ©m fidelidade Ã  imagem original
- Denoise mÃ©dio (0.5): Melhor para aprimoramentos gerais
- Denoise alto (0.7-0.8): CriaÃ§Ã£o de variaÃ§Ãµes significativas

**AplicaÃ§Ãµes do Image-to-Image:**
1. **Style Transfer:** Transformar foto em pintura
2. **Refinamento:** Melhorar qualidade de imagem
3. **VariaÃ§Ãµes:** Explorar diferentes composiÃ§Ãµes
4. **CorreÃ§Ã£o:** Ajustar iluminaÃ§Ã£o, cores

**Vantagens sobre Text-to-Image:**
- Maior controle sobre composiÃ§Ã£o
- Resultados mais previsÃ­veis
- Preserva elementos desejados
- IteraÃ§Ã£o mais rÃ¡pida

**Trade-offs:**
- Requer imagem base
- Menos "criativo" que geraÃ§Ã£o do zero
- Depende de qualidade da imagem original

**Workflow JSON:** [Conceito B.json](workflows/Conceito%20B.json)

---

### Conceito A: Text-to-Image com LoRA (TÃ©cnica AvanÃ§ada)

**Requisitos do Conceito A:**
- Conceito C completo (Text-to-Image bÃ¡sico)
- Conceito B completo (Image-to-Image)
- TÃ©cnica avanÃ§ada adicional: **LoRA (Low-Rank Adaptation)**

GeraÃ§Ã£o de imagens com estilo especializado usando **LoRA**, uma tÃ©cnica avanÃ§ada que ajusta o modelo base sem retreinamento completo.

#### Diagrama do Workflow no ComfyUI

![Workflow Text-to-Image com LoRA](outputs/A_ComfyUI.png)
*Diagrama do workflow Text-to-Image com LoRA. Note o nÃ³ adicional "Load LoRA" que modifica o modelo e o CLIP antes da geraÃ§Ã£o. A imagem pode parecer embaÃ§ada aqui devido Ã  alta resoluÃ§Ã£o - abra em nova aba ou faÃ§a download para visualizar com clareza.*

#### Arquitetura do Pipeline

```mermaid
graph TD
    A[Prompt de Texto] -->|TokenizaÃ§Ã£o| B[CLIP Text Encoder Ajustado]
    B -->|Embeddings 768D| C[Conditioning]
    D[Empty Latent Image<br/>64Ã—64Ã—4] -->|RuÃ­do AleatÃ³rio 100%| E[KSampler]
    C -->|Guia SemÃ¢ntico| E
    F[Checkpoint SD v1.5] -->|Weights Base| G[Load LoRA]
    H[Mountainscape LoRA<br/>Strength 0.8] -->|Style Adjustments| G
    G -->|Model + CLIP Ajustados| B
    G -->|Model Ajustado| E
    E -->|25 Steps| I[Latent Limpo<br/>64Ã—64Ã—4]
    I --> J[VAE Decoder]
    J -->|Upscale 8x| K[Imagem RGB<br/>512Ã—512Ã—3]
    K --> L[Save Image]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style G fill:#ffe1ff
    style H fill:#ffe1ff
    style E fill:#ffe1e1
    style J fill:#e1ffe1
    style K fill:#f0e1ff
```

#### O que Ã© LoRA?

**LoRA (Low-Rank Adaptation)** Ã© uma tÃ©cnica avanÃ§ada que permite adicionar estilos ou conceitos especÃ­ficos ao modelo base:

**Vantagens:**
- Arquivos pequenos (~10-200MB) vs modelos completos (~4GB)
- Ajusta pesos do modelo para estilos especÃ­ficos
- MÃºltiplos estilos sem trocar modelo base
- NÃ£o requer retreinamento do modelo completo

**Como funciona:**
- Adiciona camadas de baixo rank aos pesos existentes
- Modifica ligeiramente o comportamento do U-Net e CLIP
- ControlÃ¡vel atravÃ©s de parÃ¢metros de strength (0.0-1.0)

#### LoRA Utilizado

**Mountainscape LoRA - Ultimate Mountain Landscape Depiction**
- **Fonte:** [Civitai Model 1229953](https://civitai.com/models/1229953/mountainscape-lora-ultimate-mountain-landscape-depiction)
- **EspecializaÃ§Ã£o:** Paisagens montanhosas realistas e dramÃ¡ticas
- **Strength Model:** 0.8 (80% de influÃªncia no U-Net)
- **Strength CLIP:** 0.8 (80% de influÃªncia no text encoder)

#### Componentes Utilizados

| Componente | FunÃ§Ã£o | Entrada | SaÃ­da |
|------------|--------|---------|-------|
| **Load Checkpoint** | Carrega modelo base SD v1.5 | Arquivo .safetensors | MODEL, CLIP, VAE |
| **Load LoRA** | Aplica ajustes de estilo | MODEL, CLIP, LoRA file | MODEL ajustado, CLIP ajustado |
| **CLIP Text Encoder** | Converte texto com estilo | String + CLIP ajustado | Tensor 768D |
| **Empty Latent Image** | Cria ruÃ­do inicial | DimensÃµes (512Ã—512) | Latent (64Ã—64Ã—4) |
| **KSampler** | Remove ruÃ­do com modelo ajustado | Latent + MODEL LoRA | Latent limpo |
| **VAE Decoder** | Converte latent para RGB | Latent (64Ã—64Ã—4) | Imagem (512Ã—512Ã—3) |

#### Experimento Realizado

**Prompt:**
```
beautiful sunset over mountains, dramatic clouds, golden hour lighting, 
highly detailed, 8k, photorealistic, landscape photography
```

**Negative Prompt:**
```
ugly, blurry, low quality, cartoon, anime, distorted
```

#### Experimentos Realizados

**Prompt Base:**
```
beautiful sunset over mountains, dramatic clouds, golden hour lighting, 
highly detailed, 8k, photorealistic, landscape photography
```

**Negative Prompt:**
```
ugly, blurry, low quality, cartoon, anime, distorted
```

##### Teste 1: LoRA com Strength Balanceado (0.8/0.6)

**ConfiguraÃ§Ãµes:**
- **LoRA:** Mountainscape LoRA
- **Strength Model:** 0.8
- **Strength CLIP:** 0.6
- **Seed:** 123
- **Steps:** 20
- **CFG Scale:** 8.0
- **Sampler:** euler
- **Scheduler:** normal

**Resultado:**

![Conceito A - LoRA 0.8/0.6](outputs/conceitoA_lora.png)

**AnÃ¡lise:**
- InfluÃªncia forte no Modelo, moderada no CLIP
- Modelo ajustado em 80%, CLIP em 60% do texto
- Estilo montanhoso pronunciado
- Detalhes dramÃ¡ticos mantendo boa interpretaÃ§Ã£o do prompt

##### Teste 2: LoRA com Strength Moderado no Model, Alto no CLIP (0.5/1.0)

**ConfiguraÃ§Ãµes:**
- **LoRA:** Mountainscape LoRA
- **Strength Model:** 0.5 â† **MUDANÃ‡A**
- **Strength CLIP:** 1.0 â† **MUDANÃ‡A**
- **Seed:** 123
- **Steps:** 20
- **CFG Scale:** 8.0
- **Sampler:** euler
- **Scheduler:** normal

**Resultado:**

![Conceito A - LoRA 0.5/1.0](outputs/conceitoA_0.5_1.0.png)

**AnÃ¡lise:**
- CLIP totalmente ajustado (100% de influÃªncia na interpretaÃ§Ã£o do texto)
- Modelo apenas moderadamente ajustado (50%)
- CompreensÃ£o do prompt mais especializada em montanhas
- GeraÃ§Ã£o da imagem menos alterada pelo LoRA
- EquilÃ­brio interessante entre estilo original SD e especializaÃ§Ã£o

#### ComparaÃ§Ã£o entre ConfiguraÃ§Ãµes de LoRA

| Aspecto | Strength 0.8/0.6 | Strength 0.5/1.0 |
|---------|-----------------|------------------|
| **InfluÃªncia CLIP** | 60% | 100% |
| **InfluÃªncia U-Net** | 80% | 50% |
| **InterpretaÃ§Ã£o Prompt** | Muito especializada | MÃ¡xima especializaÃ§Ã£o |
| **Estilo Visual** | Forte estilo montanhoso | Estilo mais sutil |
| **Detalhes** | Altamente dramÃ¡ticos | Moderadamente dramÃ¡ticos |
| **Naturalidade** | Menos natural | Mais natural |
| **Uso Ideal** | MÃ¡ximo impacto visual | EquilÃ­brio estilo/naturalidade |

#### AnÃ¡lise de Resultados - Conceito A

**Impacto dos ParÃ¢metros de Strength:**

**Strength Model (U-Net):**
- Controla quanto o processo de geraÃ§Ã£o Ã© modificado
- Valores altos (0.8): Estilo muito presente na imagem final
- Valores mÃ©dios (0.5): Estilo sutil, mantÃ©m caracterÃ­sticas do SD base

**Strength CLIP (Text Encoder):**
- Controla como o texto Ã© interpretado
- Valores altos (1.0): MÃ¡xima influÃªncia na compreensÃ£o do prompt
- Permite que o LoRA "ensine" novos conceitos ao encoder

**CombinaÃ§Ãµes EstratÃ©gicas:**
- **0.8/0.6:** GeraÃ§Ã£o forte, interpretaÃ§Ã£o moderada
- **0.5/1.0:** InterpretaÃ§Ã£o mÃ¡xima, visual moderado
- **1.0/0.5:** Visual forte, interpretaÃ§Ã£o padrÃ£o (nÃ£o testado)

**ComparaÃ§Ã£o: Com vs Sem LoRA**

| Aspecto | Sem LoRA (Conceito C) | Com LoRA 0.8/0.6 | Com LoRA 0.5/1.0 |
|---------|----------------------|------------------|------------------|
| **Detalhes Montanhas** | GenÃ©ricos | Altamente detalhados | Detalhados |
| **ComposiÃ§Ã£o** | Variada | Focada em Ã©pico | Balanceada |
| **Atmosfera** | Natural | DramÃ¡tica | Moderadamente dramÃ¡tica |
| **Texturas** | PadrÃ£o SD v1.5 | Muito realistas | Realistas |
| **Naturalidade** | Alta | MÃ©dia | Alta |

**Vantagens:**
- ReutilizÃ¡vel em diferentes prompts
- CombinÃ¡vel com outros LoRAs
- NÃ£o modifica o modelo base permanentemente
- Permite criar bibliotecas de estilos

**Trade-offs:**
- Adiciona tempo de carregamento (~30s)
- Requer download e gerenciamento de arquivos
- Strength muito alto (>0.9) pode causar overfitting
- Nem todos os LoRAs sÃ£o compatÃ­veis entre versÃµes

**AplicaÃ§Ãµes PrÃ¡ticas:**
- Arte conceitual para jogos e filmes
- GeraÃ§Ã£o de referÃªncias visuais especializadas
- ProduÃ§Ã£o em massa com estilo consistente
- ExploraÃ§Ã£o de nichos artÃ­sticos especÃ­ficos

**Workflow JSON:** [Conceito A.json](workflows/Conceito%20A.json)

---

## Arquitetura do Stable Diffusion - ExplicaÃ§Ã£o Detalhada

### VisÃ£o Geral do Pipeline

Stable Diffusion Ã© um modelo de **difusÃ£o latente** que opera em trÃªs estÃ¡gios principais:

```mermaid
graph LR
    subgraph "EstÃ¡gio 1: Text Encoding"
        A[Prompt Text] -->|TokenizaÃ§Ã£o| B[CLIP Text Encoder]
        B -->|768 dimensÃµes| C[Text Embeddings]
    end
    
    subgraph "EstÃ¡gio 2: Denoising"
        D[Latent Noise<br/>64Ã—64Ã—4] --> E[U-Net]
        C -->|Conditioning| E
        E -->|N steps| F[Clean Latent<br/>64Ã—64Ã—4]
    end
    
    subgraph "EstÃ¡gio 3: Decoding"
        F --> G[VAE Decoder]
        G -->|8x upscale| H[RGB Image<br/>512Ã—512Ã—3]
    end
    
```

### ğŸ”¤ CLIP Text Encoder

**FunÃ§Ã£o:** Converte linguagem natural em representaÃ§Ã£o numÃ©rica compreensÃ­vel pelo modelo.

**Como funciona:**
1. Tokeniza o texto em palavras/subpalavras
2. Passa por Transformer prÃ©-treinado
3. Gera vetor de embeddings de 768 dimensÃµes
4. Embedding captura semÃ¢ntica do prompt

**Por que Ã© necessÃ¡rio:**
- U-Net nÃ£o entende texto diretamente
- CLIP foi treinado com 400M pares imagem-texto
- Permite condicionamento preciso da geraÃ§Ã£o

**Exemplo:**
```
Input:  "beautiful sunset over mountains"
Output: [0.23, -0.45, 0.78, ..., 0.12] (768 valores)
```

### U-Net (Denoising Model)

**FunÃ§Ã£o:** Remove ruÃ­do progressivamente atravÃ©s de processo iterativo condicionado.

**Arquitetura:**
- **Encoder:** Reduz resoluÃ§Ã£o, aumenta canais
- **Bottleneck:** Processa features abstratas
- **Decoder:** Aumenta resoluÃ§Ã£o, reconstrÃ³i imagem
- **Skip Connections:** Preserva detalhes entre encoder-decoder

**Processo de Denoising:**

```mermaid
gantt
    title Processo de RemoÃ§Ã£o de RuÃ­do (25 Steps)
    dateFormat X
    axisFormat %s
    
    section RuÃ­do
    100% RuÃ­do           :0, 0
    75% RuÃ­do            :5, 5
    50% RuÃ­do            :10, 10
    25% RuÃ­do            :15, 15
    5% RuÃ­do             :20, 20
    0% RuÃ­do (Imagem)    :25, 25
```

```
Step 0:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% ruÃ­do
Step 5:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 75% ruÃ­do
Step 10: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50% ruÃ­do
Step 15: [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25% ruÃ­do
Step 20: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 5% ruÃ­do
Step 25: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0% ruÃ­do â†’ Imagem
```

**Condicionamento:**
- Embedding CLIP Ã© injetado em cada step
- Guia o processo para gerar conteÃºdo relevante ao prompt
- Strength controlada por CFG (Classifier-Free Guidance)

**Por que mÃºltiplos steps:**
- RemoÃ§Ã£o gradual permite controle fino
- Evita "saltos" abruptos na geraÃ§Ã£o
- 20-30 steps = bom equilÃ­brio qualidade/tempo

### ğŸ¨ VAE (Variational Autoencoder)

**FunÃ§Ã£o:** Comprime/descomprime imagens entre espaÃ§o RGB e espaÃ§o latente.

#### VAE Encoder (Image â†’ Latent)
```
Imagem RGB: 512 Ã— 512 Ã— 3 = 786,432 valores
                â†“ (compressÃ£o 8x)
Latent:      64 Ã— 64 Ã— 4 = 16,384 valores
```

**Vantagens:**
- Reduz memÃ³ria em ~48x
- Acelera processamento do U-Net
- MantÃ©m informaÃ§Ãµes visuais importantes

#### VAE Decoder (Latent â†’ Image)
```
Latent: 64 Ã— 64 Ã— 4
           â†“ (descompressÃ£o 8x)
Imagem: 512 Ã— 512 Ã— 3
```

**Por que trabalhar em Latent Space:**
- U-Net opera em 64Ã—64 ao invÃ©s de 512Ã—512
- Reduz computaÃ§Ã£o em 64x
- Possibilita geraÃ§Ã£o em hardware comum

### KSampler (Sampling Scheduler)

**FunÃ§Ã£o:** Controla como o ruÃ­do Ã© removido ao longo dos steps.

**Algoritmos de Sampling:**

**Euler:**
- MÃ©todo mais simples
- RÃ¡pido mas pode perder detalhes
- Bom para testes rÃ¡pidos

**Euler Ancestral:**
- Adiciona ruÃ­do em cada step (estocÃ¡stico)
- Maior variabilidade
- Resultados menos previsÃ­veis

**DPM++ 2M:** (Usado neste projeto)
- Ordem superior, mais preciso
- Melhor qualidade geral
- Equilibra velocidade e qualidade

**DPM++ SDE:**
- Ainda mais detalhado
- Mais lento
- Melhor para alta qualidade

### ParÃ¢metros de Controle

#### CFG Scale (Classifier-Free Guidance)
```
CFG = 1:  Ignora prompt (aleatÃ³ rio)
CFG = 7:  EquilÃ­brio (recomendado)
CFG = 15: Segue prompt rigidamente
```

**Funcionamento:**
- U-Net gera duas prediÃ§Ãµes: com e sem condicionamento
- CFG controla quanto usar cada uma
- Maior CFG = mais aderÃªncia ao prompt

#### Steps
```
Steps = 10:  RÃ¡pido, qualidade OK
Steps = 25:  Bom equilÃ­brio
Steps = 50:  Alta qualidade, retorno diminuÃ­do
```

#### Seed
- Controla estado inicial do gerador aleatÃ³rio
- Mesma seed = mesma imagem (com mesmos parÃ¢metros)
- Importante para reprodutibilidade

---

## ComparaÃ§Ã£o entre os TrÃªs Workflows

```mermaid
graph TB
    subgraph "Conceito A: Text-to-Image + LoRA"
        A0[RuÃ­do 100%] --> B0[U-Net + LoRA]
        C0[Prompt] --> B0
        L0[LoRA Weights] -.->|Ajusta Estilo| B0
        B0 --> D0[VAE Decoder]
        D0 --> E0[Imagem Estilizada]
        
        style A0 fill:#ffe1e1
        style L0 fill:#ffe1ff
        style E0 fill:#ffe1ff
    end
    
    subgraph "Conceito C: Text-to-Image"
        A1[RuÃ­do 100%] --> B1[U-Net]
        C1[Prompt] --> B1
        B1 --> D1[VAE Decoder]
        D1 --> E1[Imagem Nova]
        
        style A1 fill:#ffe1e1
        style E1 fill:#e1ffe1
    end
    
    subgraph "Conceito B: Image-to-Image"
        A2[Imagem Base] --> B2[VAE Encoder]
        B2 --> C2[Latent + RuÃ­do parcial]
        C2 --> D2[U-Net]
        E2[Prompt] --> D2
        D2 --> F2[VAE Decoder]
        F2 --> G2[Imagem Transformada]
        
        style A2 fill:#e1f5ff
        style C2 fill:#ffe1e1
        style G2 fill:#e1ffe1
    end
```

### Tabela Comparativa Completa

| Aspecto | Conceito A (LoRA) | Conceito C (Text-to-Image) | Conceito B (Image-to-Image) |
|---------|-------------------|---------------------------|------------------------------|
| **Entrada Inicial** | RuÃ­do aleatÃ³rio 100% | RuÃ­do aleatÃ³rio 100% | Imagem codificada + ruÃ­do |
| **TÃ©cnica Especial** | LoRA (Low-Rank Adaptation) | Nenhuma | Controle de denoise |
| **VAE Usage** | Apenas Decoder | Apenas Decoder | Encoder + Decoder |
| **Denoise** | Fixo em 1.0 | Fixo em 1.0 | VariÃ¡vel (0.3-0.8) |
| **Controle** | Prompt + Estilo LoRA | Apenas prompt | Prompt + imagem base |
| **Complexidade** | Alta | Baixa | MÃ©dia |
| **Criatividade** | Alta (direcionada) | Alta | Moderada |
| **Previsibilidade** | MÃ©dia | Baixa | Alta |
| **Velocidade** | MÃ©dia (~2-5 min) | RÃ¡pida (~2-4 min) | MÃ©dia (~2-5 min) |
| **Uso Ideal** | Estilos especÃ­ficos | CriaÃ§Ã£o original | ModificaÃ§Ã£o/refinamento |
| **DependÃªncias** | Prompt + arquivo LoRA | Prompt | Prompt + imagem base |
| **NÃ­vel** | AvanÃ§ado | BÃ¡sico | IntermediÃ¡rio |

### Quando Usar Cada Workflow

**Conceito A (LoRA):**
- âœ… Quando precisa de estilo consistente e especializado
- âœ… Gerar conteÃºdo em um gÃªnero especÃ­fico (fantasia, sci-fi, realista)
- âœ… Melhorar qualidade em domÃ­nios especÃ­ficos (retratos, paisagens)
- âœ… ProduÃ§Ã£o em larga escala com identidade visual

**Conceito C (Text-to-Image BÃ¡sico):**
- âœ… ExploraÃ§Ã£o criativa inicial
- âœ… GeraÃ§Ã£o rÃ¡pida de conceitos
- âœ… Quando nÃ£o hÃ¡ requisitos de estilo especÃ­fico
- âœ… Prototipagem e iteraÃ§Ã£o rÃ¡pida

**Conceito B (Image-to-Image):**
- âœ… Refinar ou corrigir imagens existentes
- âœ… Manter composiÃ§Ã£o controlando transformaÃ§Ã£o
- âœ… Aplicar style transfer
- âœ… IteraÃ§Ã£o sobre resultados anteriores

---

## AnÃ¡lise e Descobertas

### Aprendizados sobre Stable Diffusion

**1. ImportÃ¢ncia do Latent Space:**
- Trabalhar em 64Ã—64 ao invÃ©s de 512Ã—512 Ã© crucial
- Viabiliza uso em hardware comum
- Trade-off: perde alguns detalhes finos

**2. Processo de DifusÃ£o:**
- RemoÃ§Ã£o gradual de ruÃ­do Ã© mais eficaz que geraÃ§Ã£o direta
- Permite controle fino atravÃ©s de prompts
- 25 steps oferece bom equilÃ­brio

**3. Papel do CLIP:**
- Ponte entre linguagem e visÃ£o
- Qualidade do prompt afeta drasticamente resultado
- Prompts detalhados = resultados melhores

### LimitaÃ§Ãµes Encontradas

**Hardware:**
- 7.9GB RAM no limite para SD v1.5
- NecessÃ¡rio configuraÃ§Ãµes de baixa memÃ³ria
- CPU lento (~2-5 min por imagem)

**Qualidade:**
- Anatomia Ã s vezes incorreta
- Texto em imagens geralmente ilegÃ­vel
- Detalhes muito pequenos podem se perder

**Controle:**
- DifÃ­cil controlar posicionamento exato
- CFG muito alto pode saturar cores
- Resultados ainda tÃªm elemento aleatÃ³rio

### Melhores PrÃ¡ticas Identificadas

**Prompts:**
- Seja especÃ­fico e detalhado
- Inclua qualificadores (8k, detailed, professional)
- Use negative prompts fortes

**ParÃ¢metros:**
- CFG 7.5-8.5 para maioria dos casos
- 25-30 steps suficientes
- dpmpp_2m como sampler padrÃ£o

**Workflow:**
- Text-to-Image para criaÃ§Ã£o inicial
- Image-to-Image para refinamento
- Itere com seeds diferentes

---

## ConclusÃµes

### Objetivos AlcanÃ§ados

- ImplementaÃ§Ã£o de 2 workflows funcionais
- ExplicaÃ§Ã£o completa da arquitetura Stable Diffusion
- AnÃ¡lise detalhada de CLIP, U-Net e VAE
- ExperimentaÃ§Ã£o com mÃºltiplos parÃ¢metros
- ComparaÃ§Ã£o entre diferentes abordagens

### Principais Descobertas

**Arquiteturais:**
1. Latent Diffusion Models sÃ£o eficientes por trabalharem em espaÃ§o comprimido
2. CLIP Ã© fundamental para condicionamento semÃ¢ntico
3. U-Net com skip connections preserva detalhes importantes
4. VAE permite trade-off entre qualidade e eficiÃªncia

**PrÃ¡ticas:**
1. Denoise controla equilÃ­brio preservaÃ§Ã£o-transformaÃ§Ã£o
2. CFG scale afeta aderÃªncia ao prompt
3. Samplers diferentes tÃªm caracterÃ­sticas Ãºnicas
4. Seeds permitem reprodutibilidade

### AplicaÃ§Ãµes PrÃ¡ticas

**Text-to-Image:**
- Concept art e ideaÃ§Ã£o
- GeraÃ§Ã£o de referÃªncias visuais
- ExploraÃ§Ã£o criativa
- Prototipagem rÃ¡pida

**Image-to-Image:**
- Refinamento de imagens
- Style transfer
- CorreÃ§Ã£o e aprimoramento
- VariaÃ§Ãµes controladas

### Trabalhos Futuros

- [ ] Experimentar com LoRA para estilos especÃ­ficos
- [ ] Testar ControlNet para controle estrutural
- [ ] Explorar Stable Diffusion XL (SDXL)
- [ ] Implementar inpainting para ediÃ§Ãµes localizadas
- [ ] Criar pipeline automatizado de geraÃ§Ã£o em batch

---

## ğŸ“š ReferÃªncias

1. **Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2022).** High-Resolution Image Synthesis with Latent Diffusion Models. *CVPR 2022*. [arXiv:2112.10752](https://arxiv.org/abs/2112.10752)

2. **Radford, A., Kim, J. W., Hallacy, C., et al. (2021).** Learning Transferable Visual Models From Natural Language Supervision. *ICML 2021*. [arXiv:2103.00020](https://arxiv.org/abs/2103.00020)

3. **Ho, J., Jain, A., & Abbeel, P. (2020).** Denoising Diffusion Probabilistic Models. *NeurIPS 2020*. [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)

4. **Song, J., Meng, C., & Ermon, S. (2020).** Denoising Diffusion Implicit Models. *ICLR 2021*. [arXiv:2010.02502](https://arxiv.org/abs/2010.02502)

5. **ComfyUI.** (2024). ComfyUI: A powerful and modular stable diffusion GUI. [GitHub Repository](https://github.com/comfyanonymous/ComfyUI)

6. **Stability AI.** (2024). Stable Diffusion. [Official Website](https://stability.ai/)

---

## Arquivos do Projeto

### Workflows
- [`Conceito A.json`](workflows/Conceito%20A.json) - Text-to-Image com LoRA (tÃ©cnica avanÃ§ada)
- [`Conceito C (1).json`](workflows/Conceito%20C%20(1).json) - Text-to-Image bÃ¡sico
- [`Conceito B.json`](workflows/Conceito%20B.json) - Image-to-Image workflow

### Imagens Geradas
- **Conceito A:** 2 variaÃ§Ãµes com LoRA Mountainscape (strengths 0.8/0.6 e 0.5/1.0)
- **Conceito C:** 5 variaÃ§Ãµes explorando seeds, CFG, steps, samplers
- **Conceito B:** 3 transformaÃ§Ãµes com denoise variÃ¡vel (0.30, 0.50, 0.75)

### DocumentaÃ§Ã£o
- `README.md` - Este relatÃ³rio
- `analise_workflows.ipynb` - AnÃ¡lises em Jupyter Notebook
- `GUIA_COMPLETO.md` - Guia passo a passo de implementaÃ§Ã£o

---

## AvaliaÃ§Ã£o

**Conceito C alcanÃ§ado:**
- 1 implementaÃ§Ã£o (Text-to-Image bÃ¡sico)
- ExplicaÃ§Ã£o da arquitetura
- 5 exemplos com parÃ¢metros diferentes

**Conceito B alcanÃ§ado:**
- 2 implementaÃ§Ãµes distintas:
  1. Text-to-Image (Conceito C)
  2. Image-to-Image com controle de denoise
- Arquitetura explicada para ambos workflows
- Input-output pairs documentados com 3 variaÃ§Ãµes de denoise (0.30, 0.50, 0.75)
- AnÃ¡lise comparativa detalhada entre os workflows

**Conceito A alcanÃ§ado:**
- âœ… Conceito B completo (2 implementaÃ§Ãµes acima)
- âœ… TÃ©cnica avanÃ§ada adicional implementada: **LoRA (Low-Rank Adaptation)**
- âœ… Terceiro workflow: Text-to-Image com LoRA Mountainscape
- âœ… AnÃ¡lise comparativa demonstrando impacto do LoRA
- âœ… DocumentaÃ§Ã£o completa da tÃ©cnica avanÃ§ada e seus parÃ¢metros
- âœ… ComparaÃ§Ã£o entre os 3 workflows (A, B, C)

**Total de implementaÃ§Ãµes:** 3 workflows distintos
1. Text-to-Image bÃ¡sico (Conceito C)
2. Image-to-Image (Conceito B)
3. Text-to-Image + LoRA (Conceito A - tÃ©cnica avanÃ§ada)

---

**Data de ConclusÃ£o:** 19 de Novembro de 2025  
**Status:** Completo (Conceitos A, B e C alcanÃ§ados)

---

## Arquitetura do Stable Diffusion

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLIP Text Encoder                                  â”‚
â”‚  - Entrada: "a beautiful sunset over mountains"     â”‚
â”‚  - SaÃ­da: Embedding (768 dimensÃµes)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  U-Net (Denoising Model)                            â”‚
â”‚  - Entrada: RuÃ­do aleatÃ³rio + Embedding CLIP        â”‚
â”‚  - Processo: Remove ruÃ­do em N steps                â”‚
â”‚  - SaÃ­da: Latent limpo (64Ã—64Ã—4)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VAE Decoder                                        â”‚
â”‚  - Entrada: Latent (64Ã—64Ã—4)                        â”‚
â”‚  - SaÃ­da: Imagem RGB (512Ã—512Ã—3)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CLIP Text Encoder
- **FunÃ§Ã£o:** Converte texto em representaÃ§Ã£o numÃ©rica
- **Arquitetura:** Transformer prÃ©-treinado
- **Por quÃª?** Permite que o modelo "entenda" o prompt

### U-Net
- **FunÃ§Ã£o:** Remove ruÃ­do iterativamente
- **Arquitetura:** CNN com skip connections
- **Processo:** Prediz e remove ruÃ­do em cada step

### VAE (Variational Autoencoder)
- **Encoder:** Imagem â†’ Latent comprimido (8x menor)
- **Decoder:** Latent â†’ Imagem RGB
- **Vantagem:** Reduz memÃ³ria e tempo de processamento

---

## AnÃ¡lise de ParÃ¢metros

### CFG Scale (Classifier-Free Guidance)
- **Baixo (6-7):** Mais criatividade, pode desviar do prompt
- **MÃ©dio (7.5-8):** EquilÃ­brio ideal
- **Alto (9-10):** Segue prompt rigidamente, pode perder qualidade

### Sampling Steps
- **20 steps:** RÃ¡pido, qualidade aceitÃ¡vel
- **30 steps:** Melhor qualidade
- **50+ steps:** Retorno diminuÃ­do

### Samplers
- **Euler:** Mais rÃ¡pido e simples
- **Euler Ancestral:** Adiciona variaÃ§Ã£o estocÃ¡stica
- **DPM++ 2M:** Melhor qualidade geral
- **DPM++ SDE:** Mais detalhes, mais lento

---


## Como Reproduzir

### 1. Instalar ComfyUI
```bash
git clone https://github.com/comfyanonymous/ComfyUI
cd ComfyUI
pip install -r requirements.txt
```

### 2. Baixar Modelo
- Modelo: Stable Diffusion v1.5 Pruned
- Local: `models/checkpoints/v1-5-pruned-emaonly.safetensors`

### 3. Executar ComfyUI
```bash
python main.py --cpu
```

